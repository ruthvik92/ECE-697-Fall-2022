# ECE-697-Fall-2022
ECE-697-Fall-2022

# Sources
**Open source Transformer implementations**

* [attention-is-all-you-need-pytorch](https://github.com/ruthvik92/attention-is-all-you-need-pytorch)
* [FrancescoSaverioZuppichini-ViT](https://github.com/ruthvik92/ViT)
* [vision-transformers-cifar10](https://github.com/ruthvik92/vision-transformers-cifar10)
* [ViT-pytorch-1](https://github.com/ruthvik92/ViT-pytorch-1)

**Some useful schedulers**
* [pytorch_warmup](https://github.com/ruthvik92/pytorch_warmup)
* [pytorch-cosine-annealing-with-warmup](https://github.com/ruthvik92/pytorch-cosine-annealing-with-warmup)

# Note
Our implementation will borrow many things from the above repositories but we will be adding/modifying according to our needs.

# Some details
* Add `sys.path.insert(0,'/home/,user-name>/ECE-697-Fall-2022')` to the top sections of notebooks.
* `notebooks` directory has vision and sentiment classification transformer notebooks. 
