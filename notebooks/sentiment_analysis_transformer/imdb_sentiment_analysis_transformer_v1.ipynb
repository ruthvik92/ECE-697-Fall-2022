{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-j8oyruri because the default path (/home/visionteam/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "import torch, sys, os, time\n",
    "import dill as pickle\n",
    "import torch.nn as nn\n",
    "import torch, torchtext \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import transformer.Constants as Constants\n",
    "from transformer.Layers import EncoderLayer, DecoderLayer\n",
    "from torchtext.data import Field, TabularDataset, BucketIterator, Dataset\n",
    "import torch.optim as optim\n",
    "from transformer.Optim import ScheduledOptim\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "from cosine_annealing_warmup import CosineAnnealingWarmupRestarts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some environment checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torchtext version:0.8.0, Torch version:1.7.1\n",
      "Is CUDA available:True\n",
      "Device iscuda:0\n"
     ]
    }
   ],
   "source": [
    "print('Torchtext version:{}, Torch version:{}'.format(torchtext.__version__, torch.__version__))\n",
    "print('Is CUDA available:{}'.format(torch.cuda.is_available()))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device is{}'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/visionteam/tf_tutorials/imdb_dataset/imdb_fields_and_vocab.pkl\n"
     ]
    }
   ],
   "source": [
    "save_data = os.path.expanduser('~/tf_tutorials/imdb_dataset/imdb_fields_and_vocab.pkl')\n",
    "print(save_data)\n",
    "data = pickle.load(open(save_data, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = data['fields_with_and_without_vocab']\n",
    "train_data = Dataset(examples=data['train_examples'], fields=fields)\n",
    "valid_data = Dataset(examples=data['valid_examples'], fields=fields)\n",
    "test_data = Dataset(examples=data['test_examples'], fields=fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(fields['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fields['text'].vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(fields['text'].vocab).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields['text'].vocab.unk_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.examples[0].label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why use `sort=False` ?** \n",
    "* [Source 1](https://github.com/pytorch/text/issues/474)\n",
    "* [Source 2](https://stackoverflow.com/questions/58241313/understanding-typeerror-not-supported-between-instances-of-example-and-e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/visionteam/python37_env/lib/python3.7/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "train_iterator, test_iterator, valid_iterator = BucketIterator.splits(\n",
    "    (train_data, test_data, valid_data), batch_size=batch_size, device=device, sort=False\n",
    ")  #<--- bucketiterator expects a dataset object and fields that already have vocabularay built.\n",
    "n_batches = len(train_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 32])\n",
      "torch.Size([32])\n",
      "torch.Size([255, 32])\n",
      "torch.Size([32])\n",
      "torch.Size([250, 32])\n",
      "torch.Size([32])\n",
      "torch.Size([254, 32])\n",
      "torch.Size([32])\n",
      "torch.Size([251, 32])\n",
      "torch.Size([32])\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for batch in train_iterator:\n",
    "    #print(vars(batch).keys())\n",
    "    #sys.exit()\n",
    "    #print(type(print(batch.text)))\n",
    "    #sys.exit()\n",
    "    print(batch.text.shape)\n",
    "    print(batch.label.shape)\n",
    "    count += 1\n",
    "    if(count == 5):\n",
    "        sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pad_mask(seq, pad_idx):\n",
    "    return (seq != pad_idx).unsqueeze(-2)\n",
    "\n",
    "\n",
    "def get_subsequent_mask(seq):\n",
    "    ''' For masking out the subsequent info. '''\n",
    "    sz_b, len_s = seq.size()\n",
    "    subsequent_mask = (1 - torch.triu(\n",
    "        torch.ones((1, len_s, len_s), device=seq.device), diagonal=1)).bool()\n",
    "    return subsequent_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Find the batch with smallest samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "largest_seq_len = max([batch.text.shape[0] for batch in train_iterator])\n",
    "small_batch = None\n",
    "for batch in train_iterator:\n",
    "    if(batch.text.shape[0] < largest_seq_len):\n",
    "        small_batch = batch\n",
    "        largest_seq_len = batch.text.shape[0]\n",
    "print(small_batch.text.transpose(0,1))\n",
    "print(small_batch.text.shape)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Find the batch with largest samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_seq_len = max([batch.text.shape[0] for batch in train_iterator])\n",
    "smallest_seq_len = min([batch.text.shape[0] for batch in train_iterator])\n",
    "print('Length of the largest sequence:{} and the smallest sequence:{}'.format(largest_seq_len,\n",
    "                                                                             smallest_seq_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test masking functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_pad_idx = fields['text'].vocab.stoi[Constants.PAD_WORD]\n",
    "src_seq = small_batch.text.transpose(0,1)\n",
    "print('Source sequence shape:{}'.format(src_seq.shape))\n",
    "src_pad_mask = get_pad_mask(src_seq, src_pad_idx)\n",
    "src_subseq_mask = get_subsequent_mask(src_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(src_pad_mask.shape)\n",
    "print(src_pad_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(src_subseq_mask.shape)\n",
    "print(src_subseq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = src_subseq_mask.detach().squeeze(0).cpu().numpy().astype(np.int16)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_mask = src_pad_mask & src_subseq_mask\n",
    "print(src_mask)\n",
    "print(src_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(src_mask[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(src_mask[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaled dot product attention\n",
    "![alt text](scaled_dot_product_attn.png \"Scaled Dot Product Attention\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    ''' Scaled Dot-Product Attention '''\n",
    "\n",
    "    def __init__(self, temperature, attn_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.dropout = nn.Dropout(attn_dropout)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        #print(q.shape, k.shape, v.shape)\n",
    "        attn = torch.matmul(q / self.temperature, k.transpose(2, 3))\n",
    "        #print(attn.shape)\n",
    "\n",
    "        if mask is not None:\n",
    "            #print('mask:{}'.format(mask.shape))\n",
    "            attn = attn.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        attn = self.dropout(F.softmax(attn, dim=-1))\n",
    "        #print(attn.shape)\n",
    "        output = torch.matmul(attn, v)\n",
    "        #print(output.shape)\n",
    "        return output, attn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing scaled dot product attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_head = 1\n",
    "batch = 2\n",
    "sent_len = small_batch.text.shape[0]\n",
    "d_model = 512\n",
    "d_k = d_model\n",
    "temperature = d_k ** 0.5\n",
    "q = torch.Tensor(np.random.rand(batch, sent_len, n_head, d_model)).to(device=device) ##fake sentence\n",
    "k = torch.Tensor(np.random.rand(batch, sent_len, n_head, d_model)).to(device=device)\n",
    "v = torch.Tensor(np.random.rand(batch, sent_len, n_head, d_model)).to(device=device)\n",
    "print('Query, Key, and Value shapes:{}, {}, {}'.format(q.shape, k.shape, v.shape))\n",
    "scaled_dpa = ScaledDotProductAttention(temperature=temperature)\n",
    "q, k, v = q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2)\n",
    "print('Query, Key, and Value shapes:{}, {}, {}'.format(q.shape, k.shape, v.shape))\n",
    "src_mask = src_mask.unsqueeze(1)   # For head axis broadcasting.\n",
    "output, attn = scaled_dpa(q, k, v, mask=src_mask)\n",
    "print('Output shape:{}, attention shape:{}'.format(output.shape, attn.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_attn = attn.squeeze(1).cpu().numpy()\n",
    "first_attention_mask = np.round(numpy_attn[0,:,:], 5)\n",
    "second_attention_mask = np.round(numpy_attn[1,:,:], 5)\n",
    "print(first_attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(second_attention_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-head attention\n",
    "![alt text](multi-head-attention.png \"Multi-head attention\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    ''' Multi-Head Attention module '''\n",
    "\n",
    "    def __init__(self, n_head, d_model, d_k, d_v, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_head = n_head\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "\n",
    "        self.w_qs = nn.Linear(d_model, n_head * d_k, bias=False)\n",
    "        self.w_ks = nn.Linear(d_model, n_head * d_k, bias=False)\n",
    "        self.w_vs = nn.Linear(d_model, n_head * d_v, bias=False)\n",
    "        self.fc = nn.Linear(n_head * d_v, d_model, bias=False)\n",
    "\n",
    "        self.attention = ScaledDotProductAttention(temperature=d_k ** 0.5)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "\n",
    "        d_k, d_v, n_head = self.d_k, self.d_v, self.n_head\n",
    "        sz_b, len_q, len_k, len_v = q.size(0), q.size(1), k.size(1), v.size(1)\n",
    "\n",
    "        residual = q\n",
    "\n",
    "        # Pass through the pre-attention projection: b x lq x (n*dv)\n",
    "        # Separate different heads: b x lq x n x dv\n",
    "        q = self.w_qs(q).view(sz_b, len_q, n_head, d_k)\n",
    "        k = self.w_ks(k).view(sz_b, len_k, n_head, d_k)\n",
    "        v = self.w_vs(v).view(sz_b, len_v, n_head, d_v)\n",
    "\n",
    "        # Transpose for attention dot product: b x n x lq x dv\n",
    "        q, k, v = q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2)\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1)   # For head axis broadcasting.\n",
    "\n",
    "        q, attn = self.attention(q, k, v, mask=mask)\n",
    "\n",
    "        # Transpose to move the head dimension back: b x lq x n x dv\n",
    "        # Combine the last two dimensions to concatenate all the heads together: b x lq x (n*dv)\n",
    "        q = q.transpose(1, 2).contiguous().view(sz_b, len_q, -1)\n",
    "        q = self.dropout(self.fc(q))\n",
    "        q += residual\n",
    "\n",
    "        q = self.layer_norm(q)\n",
    "\n",
    "        return q, attn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing multi-head attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Generate a mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_pad_idx = fields['text'].vocab.stoi[Constants.PAD_WORD]\n",
    "src_seq = small_batch.text.transpose(0,1)\n",
    "print('Source sequence shape:{}'.format(src_seq.shape))\n",
    "src_pad_mask = get_pad_mask(src_seq, src_pad_idx)\n",
    "src_subseq_mask = get_subsequent_mask(src_seq)\n",
    "src_mask = src_pad_mask & src_subseq_mask\n",
    "print(src_mask)\n",
    "print(src_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_head = 8\n",
    "batch = 2\n",
    "sent_len = small_batch.text.shape[0]\n",
    "d_model = 512\n",
    "d_k = int(d_model / n_head)\n",
    "temperature = d_k ** 0.5\n",
    "q = torch.Tensor(np.random.rand(batch, sent_len, n_head*d_k)).to(device=device) ##fake sentence\n",
    "k = torch.Tensor(np.random.rand(batch, sent_len, n_head*d_k)).to(device=device)\n",
    "v = torch.Tensor(np.random.rand(batch, sent_len, n_head*d_k)).to(device=device)\n",
    "print('Shapes of Query:{}, Key:{}, and Value:{}'.format(q.shape, k.shape, v.shape))\n",
    "#q, k, v = q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2)\n",
    "#print('Shapes of Query:{}, Key:{}, and Value:{}'.format(q.shape, k.shape, v.shape))\n",
    "mha = MultiHeadAttention(n_head=n_head, d_model=d_model, d_k=d_k, d_v=d_k)\n",
    "mha = mha.to(device=device)\n",
    "q, attn = mha(q=q, k=k, v=v, mask=src_mask) \n",
    "print('Shapes of q:{}, and attn:{}'.format(q.shape, attn.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(src_mask[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(attn[0,0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(src_mask[1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(attn[1,0,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positionwise feedforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    ''' A two-feed-forward-layer module '''\n",
    "\n",
    "    def __init__(self, d_in, d_hid, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.w_1 = nn.Linear(d_in, d_hid) # position-wise\n",
    "        self.w_2 = nn.Linear(d_hid, d_in) # position-wise\n",
    "        self.layer_norm = nn.LayerNorm(d_in, eps=1e-6)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        residual = x\n",
    "\n",
    "        x = self.w_2(F.relu(self.w_1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x += residual\n",
    "\n",
    "        x = self.layer_norm(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder layer\n",
    "![alt text](encoder_without_positional.png \"Encoder without positional\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    ''' Compose with two layers '''\n",
    "\n",
    "    def __init__(self, d_model, d_inner, n_head, d_k, d_v, dropout=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.slf_attn = MultiHeadAttention(n_head, d_model, d_k, d_v, dropout=dropout)\n",
    "        self.pos_ffn = PositionwiseFeedForward(d_model, d_inner, dropout=dropout)\n",
    "\n",
    "    def forward(self, enc_input, slf_attn_mask=None):\n",
    "        enc_output, enc_slf_attn = self.slf_attn(\n",
    "            enc_input, enc_input, enc_input, mask=slf_attn_mask)\n",
    "        enc_output = self.pos_ffn(enc_output)\n",
    "        return enc_output, enc_slf_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the EncoderLayer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Generate a mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_pad_idx = fields['text'].vocab.stoi[Constants.PAD_WORD]\n",
    "src_seq = small_batch.text.transpose(0,1)\n",
    "print('Source sequence shape:{}'.format(src_seq.shape))\n",
    "src_pad_mask = get_pad_mask(src_seq, src_pad_idx)\n",
    "src_subseq_mask = get_subsequent_mask(src_seq)\n",
    "src_mask = src_pad_mask & src_subseq_mask\n",
    "print(src_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(src_seq[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(src_mask[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(src_seq[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(src_mask[1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512\n",
    "d_inner = 1024\n",
    "n_head = 8\n",
    "d_k = int(d_model / n_head)\n",
    "d_v = d_k\n",
    "enc_layer = EncoderLayer(d_model=d_model, d_inner=d_inner, n_head=n_head, d_k=d_k, d_v=d_v).to(device)\n",
    "q = torch.Tensor(np.random.rand(batch, sent_len, n_head*d_k)).to(device=device) ##fake sentence\n",
    "print('Shapes of Query:{}, Key:{}, and Value:{}'.format(q.shape, k.shape, v.shape))\n",
    "enc_output, enc_self_attn = enc_layer(enc_input=q, slf_attn_mask=src_mask)\n",
    "print('enc_output.shape:{}, enc_self_attn.shape:{}'.format(enc_output.shape, enc_self_attn.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(enc_self_attn[0,0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(enc_self_attn[1,0,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional encoding\n",
    "* Returns a tensor of size `n_position x d_model`, here `n_position` is the maximum number of words in your dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_hid, n_position=300):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        # Not a parameter\n",
    "        self.register_buffer('pos_table', self._get_sinusoid_encoding_table(n_position, d_hid))\n",
    "\n",
    "    def _get_sinusoid_encoding_table(self, n_position, d_hid):\n",
    "        ''' Sinusoid position encoding table '''\n",
    "\n",
    "        def get_position_angle_vec(position):\n",
    "            return [position / np.power(10000, 2 * (hid_j // 2) / d_hid) for hid_j in range(d_hid)]\n",
    "\n",
    "        sinusoid_table = np.array([get_position_angle_vec(pos_i) for pos_i in range(n_position)])\n",
    "        sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # dim 2i\n",
    "        sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # dim 2i+1\n",
    "\n",
    "        return torch.FloatTensor(sinusoid_table).unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pos_table[:, :x.size(1)].clone().detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_enc = PositionalEncoding(100, n_position=20)\n",
    "x = np.zeros(shape=(20, 100))\n",
    "x = torch.Tensor(x)  ## <--- send in an empty tensor so that we can visualize what's inside\n",
    "x_pos_enc = pos_enc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pos_enc = x_pos_enc.detach().cpu().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pos_enc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See what's in even positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    plt.plot(range(20), x_pos_enc[:,2*i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See what's in odd positions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    plt.plot(range(20), x_pos_enc[:,2*i+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole Encoder\n",
    "![alt text](whole_encoder.png \"Whole encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    ''' A encoder model with self attention mechanism. '''\n",
    "\n",
    "    def __init__(\n",
    "            self, n_src_vocab, d_word_vec, n_layers, n_head, d_k, d_v,\n",
    "            d_model, d_inner, pad_idx, dropout=0.1, n_position=300, scale_emb=False):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.src_word_emb = nn.Embedding(n_src_vocab, d_word_vec, padding_idx=pad_idx)\n",
    "        self.position_enc = PositionalEncoding(d_word_vec, n_position=n_position)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.layer_stack = nn.ModuleList([\n",
    "            EncoderLayer(d_model, d_inner, n_head, d_k, d_v, dropout=dropout)\n",
    "            for _ in range(n_layers)])\n",
    "        self.layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n",
    "        self.scale_emb = scale_emb\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, src_seq, src_mask, return_attns=False):\n",
    "\n",
    "        enc_slf_attn_list = []\n",
    "\n",
    "        # -- Forward\n",
    "        enc_output = self.src_word_emb(src_seq)\n",
    "        if self.scale_emb:\n",
    "            enc_output *= self.d_model ** 0.5\n",
    "        enc_output = self.dropout(self.position_enc(enc_output))\n",
    "        enc_output = self.layer_norm(enc_output)\n",
    "\n",
    "        for enc_layer in self.layer_stack:\n",
    "            enc_output, enc_slf_attn = enc_layer(enc_output, slf_attn_mask=src_mask)\n",
    "            enc_slf_attn_list += [enc_slf_attn] if return_attns else []\n",
    "\n",
    "        if return_attns:\n",
    "            return enc_output, enc_slf_attn_list\n",
    "        return enc_output,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the whole encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````\n",
    "d_k = int(d_model / n_head) #---> int() is very important or else you'll see\n",
    "TypeError: new() received an invalid combination of arguments - got (float, int), but expected one of:\n",
    " * (*, torch.device device)\n",
    "      didn't match because some of the arguments have invalid types: (float, int)\n",
    " * (torch.Storage storage)\n",
    " * (Tensor other)\n",
    " * (tuple of ints size, *, torch.device device)\n",
    " * (object data, *, torch.device device)\n",
    " ````\n",
    " * If you do not use `int()` then `d_k = 64.0`, and `d_k*n_head = 512.0`, and the line\n",
    " `self.w_qs = nn.Linear(d_model, n_head * d_k, bias=False)` will throw this error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'src_pad_idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-50dc75d7c750>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0md_inner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m enc = Encoder(n_src_vocab=src_vocab_size, d_word_vec=d_model, n_layers=n_layers, n_head=n_head, \n\u001b[0;32m----> 8\u001b[0;31m               d_k=d_k, d_v=d_k, d_model=d_model, d_inner=d_inner, pad_idx=src_pad_idx)\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'src_pad_idx' is not defined"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(fields['text'].vocab)\n",
    "d_model = 512\n",
    "n_layers = 6\n",
    "n_head = 8\n",
    "d_k = int(d_model / n_head)\n",
    "d_inner = 1024\n",
    "enc = Encoder(n_src_vocab=src_vocab_size, d_word_vec=d_model, n_layers=n_layers, n_head=n_head, \n",
    "              d_k=d_k, d_v=d_k, d_model=d_model, d_inner=d_inner, pad_idx=src_pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_seq = small_batch.text.transpose(0,1)\n",
    "print('Source sequence shape:{}'.format(src_seq.shape))\n",
    "src_pad_mask = get_pad_mask(src_seq, src_pad_idx)\n",
    "src_subseq_mask = get_subsequent_mask(src_seq)\n",
    "src_mask = src_pad_mask & src_subseq_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_pad_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_seq[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_seq[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(src_mask[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(src_mask[1,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* One has to explicitly place the model on the GPU or else, it will reside on the CPU\n",
    "* `RuntimeError: Input, output and indices must be on the current device`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = enc.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_op, enc_self_attn_list = enc(src_seq=src_seq, src_mask=src_mask, return_attns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('enc_op.shape:{}'.format(enc_op.shape))\n",
    "print('enc_self_attn_list shapes:{}'.format([item.shape for item in enc_self_attn_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(enc_self_attn_list[0][0,0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(enc_self_attn_list[0][1,0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(enc_self_attn_list[-1][0,0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(enc_self_attn_list[-1][1,0,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier with learnable pooling \n",
    "\n",
    "* the below code performs $R^{2 \\times 65 \\times 512} \\rightarrow R^{2 \\times 1 \\times 512}$ assuming  $d\\_model \\in R^{512}$, $enc\\_output \\in R^{2 \\times 65 \\times 512}$, and the batch size is 2. The same is implemented in the below class `ClassificationHeadWithLearnablePooling` lines `10-14`.\n",
    "\n",
    "`temp_layer = nn.Linear(d_model, 1)`\n",
    "\n",
    "`temp_layer_op = temp_layer(enc_output)`\n",
    "\n",
    "`print(temp_layer_op.shape)`\n",
    "\n",
    "torch.Size([2, 65, 1])\n",
    "\n",
    "`temp_layer_op = temp_layer_op.transpose(-1, 1)`\n",
    "\n",
    "`temp_layer_op = F.softmax(temp_layer_op, dim=-1)` #softmax(g(XL)T) in R^{bx1xn}\n",
    "\n",
    "`print(temp_layer_op.shape)`\n",
    "\n",
    "torch.Size([2, 1, 65])\n",
    "\n",
    "`temp_z = torch.matmul(temp_layer_op, enc_output)` #[2,1,65]x[2,65,512], softmax(g(XL)T) x XL in R^{bx1xd} \n",
    "\n",
    "`print(temp_z.shape)`\n",
    "\n",
    "torch.Size([2, 1, 512])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationHeadWithLearnablePooling(nn.Module):\n",
    "    def __init__(self, d_model: int = 512, n_classes: int = 2):\n",
    "        super().__init__()\n",
    "        self.reduction_layer = nn.Linear(d_model, 1)\n",
    "        self.layer_norm = nn.LayerNorm(d_model) \n",
    "        self.linear_layer = nn.Linear(d_model, n_classes)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        ### Learnable pooling\n",
    "        reduction_layer_op = self.reduction_layer(x)\n",
    "        reduction_layer_op = reduction_layer_op.transpose(-1, 1)\n",
    "        reduction_layer_op = F.softmax(reduction_layer_op, dim=-1)\n",
    "        enc_output = torch.matmul(reduction_layer_op, x)\n",
    "        enc_output = enc_output.squeeze(1) #converts torch.Size([2, 1, 512]) -> torch.Size([2, 512])\n",
    "        ## end of learnable pooling\n",
    "        \n",
    "        ## layer norm and a fully connected layer\n",
    "        layer_normed_reduced = self.layer_norm(enc_output)\n",
    "        output = self.linear_layer(layer_normed_reduced)\n",
    "        #output = self.linear_layer(enc_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentTransformer(nn.Module):\n",
    "    def __init__(\n",
    "            self, n_src_vocab, d_word_vec, n_layers, n_head, d_k, d_v,\n",
    "            d_model, d_inner, pad_idx, n_classes, dropout=0.1, n_position=300, scale_emb=False,\n",
    "    return_attns=True):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.return_attns = return_attns\n",
    "\n",
    "        self.encoder = Encoder(\n",
    "            n_src_vocab=n_src_vocab, n_position=n_position,\n",
    "            d_word_vec=d_word_vec, d_model=d_model, d_inner=d_inner,\n",
    "            n_layers=n_layers, n_head=n_head, d_k=d_k, d_v=d_v,\n",
    "            pad_idx=src_pad_idx, dropout=dropout, scale_emb=scale_emb)\n",
    "        \n",
    "        self.classifier_head = ClassificationHeadWithLearnablePooling(d_model=d_model, \n",
    "                                                                      n_classes=n_classes)\n",
    "    \n",
    "    def forward(self, src_seq: torch.Tensor) -> torch.Tensor:\n",
    "        src_mask = get_pad_mask(src_seq, self.src_pad_idx) & get_subsequent_mask(src_seq)\n",
    "        encoder_op, enc_self_attn = self.encoder(src_seq, src_mask,return_attns=self.return_attns)\n",
    "        classifier_op = self.classifier_head(encoder_op)\n",
    "        if(self.return_attns):\n",
    "            return classifier_op, enc_self_attn\n",
    "        else:\n",
    "            return classifier_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the complete sentiment analysis transformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab_size = len(fields['text'].vocab)\n",
    "d_model = 512\n",
    "n_layers = 6\n",
    "n_head = 8\n",
    "d_k = int(d_model / n_head)\n",
    "src_pad_idx = fields['text'].vocab.stoi[Constants.PAD_WORD]\n",
    "d_inner = 1024\n",
    "n_classes = 2\n",
    "return_attns=True\n",
    "sentiment_trf = SentimentTransformer(n_src_vocab=src_vocab_size, d_word_vec=d_model, n_layers=n_layers,\n",
    "                                    n_head=n_head, d_k=d_k, d_v=d_k, d_model=d_model, d_inner=d_inner,\n",
    "                                    pad_idx=src_pad_idx, n_classes=n_classes, return_attns=return_attns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_trf = sentiment_trf.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_seq = small_batch.text.transpose(0,1)\n",
    "print('Source sequence shape:{}'.format(src_seq.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_op = sentiment_trf(src_seq=src_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('classifier_op.shape:{}'.format(classifier_op.shape))\n",
    "print('classifier_op:{}'.format(classifier_op))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a learning rate scheduler (Cosine annealed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of batches(steps):400000\n",
      "Steps (batches) for the first cycle to complete:40000\n",
      "Minimum learning rate:0.005 and maximum learning rate:0.03 for this scheduler\n",
      "Warmup steps:20000\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "gamma = 0.88\n",
    "n_steps = epochs*n_batches\n",
    "print('Total number of batches(steps):{}'.format(n_steps))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.03\n",
    "optimizer = optim.SGD(sentiment_trf.parameters(), lr=lr, momentum=0.9)\n",
    "first_cycle_steps=int(n_batches*50) ## after 50 epochs, a cycle is completed.\n",
    "print('Steps (batches) for the first cycle to complete:{}'.format(first_cycle_steps))\n",
    "min_lr = lr / 6\n",
    "print('Minimum learning rate:{} and maximum learning rate:{} for this scheduler'.format(min_lr, lr))\n",
    "warmup_steps = int(first_cycle_steps / 2.0)\n",
    "print('Warmup steps:{}'.format(warmup_steps))\n",
    "scheduler = CosineAnnealingWarmupRestarts(optimizer, first_cycle_steps=first_cycle_steps, cycle_mult=1.0, \n",
    "                                          max_lr=lr, min_lr=min_lr, warmup_steps=warmup_steps, gamma=gamma) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Learning rate')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrs = []\n",
    "for i in range(n_steps):\n",
    "    lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "    scheduler.step()\n",
    "plt.plot(list(range(len(lrs))), lrs)\n",
    "plt.grid()\n",
    "plt.xlabel('Steps (batches)')\n",
    "plt.ylabel('Learning rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a learning rate scheduler (warm start)\n",
    "* Used in the `Attention is all you need paper`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of batches(steps):400000\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "n_steps = epochs*n_batches\n",
    "n_warmup_steps = n_batches*50\n",
    "print('Total number of batches(steps):{}'.format(n_steps))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.03\n",
    "optimizer = optim.SGD(sentiment_trf.parameters(), lr=lr, momentum=0.9)\n",
    "scheduled_optimizer = ScheduledOptim(optimizer, 50.0, d_model, n_warmup_steps) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Learning rate')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrs = []\n",
    "for i in range(n_steps):\n",
    "    lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "    scheduled_optimizer.update_lr()\n",
    "lrs = lrs[1:]\n",
    "plt.plot(list(range(len(lrs))), lrs)\n",
    "plt.grid()\n",
    "plt.xlabel('Steps (batches)')\n",
    "plt.ylabel('Learning rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-start the scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_type = 'learnable_pooling'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = CosineAnnealingWarmupRestarts(optimizer, first_cycle_steps=first_cycle_steps, cycle_mult=1.0, \n",
    "                                          max_lr=lr, min_lr=min_lr, warmup_steps=warmup_steps, gamma=gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoints will be saved to:./imdb_net_learnable_pooling_sgd_lr_0.00599875_gamma_0.88_500_epochs_32_batch.pth\n"
     ]
    }
   ],
   "source": [
    "PATH = './imdb_net_{}_sgd_lr_{}_gamma_{}_{}_epochs_{}_batch.pth'.format(classifier_type, lr, gamma, \n",
    "                                                                           epochs, batch_size)\n",
    "print('Checkpoints will be saved to:{}'.format(PATH))\n",
    "def save_checkpoint(model, path):\n",
    "    print('Saved checkpoint to:{}'.format(path))\n",
    "    torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in test_iterator:\n",
    "            texts, labels = data.text.transpose(0,1).to(device), data.label.to(device)\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = sentiment_trf(texts)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print('Accuracy of the network on the {} test sentences:{}'.format(total, accuracy))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([242, 32])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 3268 test sentences:50.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   800] loss: 0.542063\n",
      "Learning rate:0.00799625\n",
      "Accuracy of the network on the 3268 test sentences:73.77600979192167\n",
      "Saved checkpoint to:./imdb_net_learnable_pooling_sgd_lr_0.00599875_gamma_0.88_500_epochs_32_batch.pth\n",
      "Time elapsed for epoch:1 is:163.56228923797607\n",
      "[2,   800] loss: 0.491933\n",
      "Learning rate:0.00899625\n",
      "Accuracy of the network on the 3268 test sentences:73.43941248470013\n",
      "Time elapsed for epoch:2 is:164.4569706916809\n",
      "[3,   800] loss: 0.453747\n",
      "Learning rate:0.00999625\n",
      "Accuracy of the network on the 3268 test sentences:77.87637698898409\n",
      "Saved checkpoint to:./imdb_net_learnable_pooling_sgd_lr_0.00599875_gamma_0.88_500_epochs_32_batch.pth\n",
      "Time elapsed for epoch:3 is:165.4962282180786\n",
      "[4,   800] loss: 0.401920\n",
      "Learning rate:0.010996249999999999\n",
      "Accuracy of the network on the 3268 test sentences:82.03794369645043\n",
      "Saved checkpoint to:./imdb_net_learnable_pooling_sgd_lr_0.00599875_gamma_0.88_500_epochs_32_batch.pth\n",
      "Time elapsed for epoch:4 is:165.49088668823242\n",
      "[5,   800] loss: 0.369212\n",
      "Learning rate:0.01199625\n",
      "Accuracy of the network on the 3268 test sentences:82.77233782129743\n",
      "Saved checkpoint to:./imdb_net_learnable_pooling_sgd_lr_0.00599875_gamma_0.88_500_epochs_32_batch.pth\n",
      "Time elapsed for epoch:5 is:165.17197132110596\n",
      "[6,   800] loss: 0.349706\n",
      "Learning rate:0.01299625\n",
      "Accuracy of the network on the 3268 test sentences:83.69033047735618\n",
      "Saved checkpoint to:./imdb_net_learnable_pooling_sgd_lr_0.00599875_gamma_0.88_500_epochs_32_batch.pth\n",
      "Time elapsed for epoch:6 is:165.72018909454346\n",
      "[7,   800] loss: 0.320982\n",
      "Learning rate:0.013996249999999998\n",
      "Accuracy of the network on the 3268 test sentences:83.17013463892289\n",
      "Time elapsed for epoch:7 is:165.9040172100067\n",
      "[8,   800] loss: 0.299974\n",
      "Learning rate:0.01499625\n",
      "Accuracy of the network on the 3268 test sentences:82.2827417380661\n",
      "Time elapsed for epoch:8 is:165.54459762573242\n",
      "[9,   800] loss: 0.274874\n",
      "Learning rate:0.01599625\n",
      "Accuracy of the network on the 3268 test sentences:84.21052631578948\n",
      "Saved checkpoint to:./imdb_net_learnable_pooling_sgd_lr_0.00599875_gamma_0.88_500_epochs_32_batch.pth\n",
      "Time elapsed for epoch:9 is:165.8253448009491\n",
      "[10,   800] loss: 0.260109\n",
      "Learning rate:0.01699625\n",
      "Accuracy of the network on the 3268 test sentences:79.10036719706243\n",
      "Time elapsed for epoch:10 is:165.99479699134827\n",
      "[11,   800] loss: 0.238771\n",
      "Learning rate:0.01799625\n",
      "Accuracy of the network on the 3268 test sentences:84.42472460220318\n",
      "Saved checkpoint to:./imdb_net_learnable_pooling_sgd_lr_0.00599875_gamma_0.88_500_epochs_32_batch.pth\n",
      "Time elapsed for epoch:11 is:166.14873433113098\n",
      "[12,   800] loss: 0.219013\n",
      "Learning rate:0.01899625\n",
      "Accuracy of the network on the 3268 test sentences:83.69033047735618\n",
      "Time elapsed for epoch:12 is:165.89574122428894\n",
      "[13,   800] loss: 0.194266\n",
      "Learning rate:0.019996249999999997\n",
      "Accuracy of the network on the 3268 test sentences:85.03671970624235\n",
      "Saved checkpoint to:./imdb_net_learnable_pooling_sgd_lr_0.00599875_gamma_0.88_500_epochs_32_batch.pth\n",
      "Time elapsed for epoch:13 is:166.14070320129395\n",
      "[14,   800] loss: 0.175872\n",
      "Learning rate:0.020996249999999998\n",
      "Accuracy of the network on the 3268 test sentences:85.46511627906976\n",
      "Saved checkpoint to:./imdb_net_learnable_pooling_sgd_lr_0.00599875_gamma_0.88_500_epochs_32_batch.pth\n",
      "Time elapsed for epoch:14 is:166.257395029068\n",
      "[15,   800] loss: 0.169438\n",
      "Learning rate:0.02199625\n",
      "Accuracy of the network on the 3268 test sentences:84.17992656058752\n",
      "Time elapsed for epoch:15 is:165.68761825561523\n",
      "[16,   800] loss: 0.152973\n",
      "Learning rate:0.02299625\n",
      "Accuracy of the network on the 3268 test sentences:84.70012239902081\n",
      "Time elapsed for epoch:16 is:165.50995898246765\n",
      "[17,   800] loss: 0.141156\n",
      "Learning rate:0.02399625\n",
      "Accuracy of the network on the 3268 test sentences:83.65973072215422\n",
      "Time elapsed for epoch:17 is:165.64082050323486\n",
      "[18,   800] loss: 0.142396\n",
      "Learning rate:0.024996249999999998\n",
      "Accuracy of the network on the 3268 test sentences:85.28151774785802\n",
      "Time elapsed for epoch:18 is:165.3022334575653\n",
      "[19,   800] loss: 0.143228\n",
      "Learning rate:0.02599625\n",
      "Accuracy of the network on the 3268 test sentences:82.80293757649939\n",
      "Time elapsed for epoch:19 is:165.03126788139343\n",
      "[20,   800] loss: 0.131797\n",
      "Learning rate:0.02699625\n",
      "Accuracy of the network on the 3268 test sentences:83.41493268053856\n",
      "Time elapsed for epoch:20 is:164.59252214431763\n",
      "[21,   800] loss: 0.126957\n",
      "Learning rate:0.02799625\n",
      "Accuracy of the network on the 3268 test sentences:84.91432068543452\n",
      "Time elapsed for epoch:21 is:164.73079323768616\n",
      "[22,   800] loss: 0.129695\n",
      "Learning rate:0.028996249999999998\n",
      "Accuracy of the network on the 3268 test sentences:85.70991432068543\n",
      "Saved checkpoint to:./imdb_net_learnable_pooling_sgd_lr_0.00599875_gamma_0.88_500_epochs_32_batch.pth\n",
      "Time elapsed for epoch:22 is:164.8768274784088\n",
      "[23,   800] loss: 0.123903\n",
      "Learning rate:0.02999625\n",
      "Accuracy of the network on the 3268 test sentences:85.40391676866585\n",
      "Time elapsed for epoch:23 is:164.53105521202087\n",
      "[24,   800] loss: 0.122592\n",
      "Learning rate:0.02990217066312057\n",
      "Accuracy of the network on the 3268 test sentences:84.39412484700122\n",
      "Time elapsed for epoch:24 is:167.13130831718445\n",
      "[25,   800] loss: 0.114369\n",
      "Learning rate:0.02960875307409918\n",
      "Accuracy of the network on the 3268 test sentences:82.77233782129743\n",
      "Time elapsed for epoch:25 is:181.88201785087585\n",
      "[26,   800] loss: 0.101932\n",
      "Learning rate:0.029124373215680777\n",
      "Accuracy of the network on the 3268 test sentences:85.83231334149326\n",
      "Saved checkpoint to:./imdb_net_learnable_pooling_sgd_lr_0.00599875_gamma_0.88_500_epochs_32_batch.pth\n",
      "Time elapsed for epoch:26 is:167.57915425300598\n",
      "[27,   800] loss: 0.090228\n",
      "Learning rate:0.028456670047587125\n",
      "Accuracy of the network on the 3268 test sentences:84.8531211750306\n",
      "Time elapsed for epoch:27 is:164.71501541137695\n",
      "[28,   800] loss: 0.087958\n",
      "Learning rate:0.027616173647645587\n",
      "Accuracy of the network on the 3268 test sentences:85.28151774785802\n",
      "Time elapsed for epoch:28 is:164.72939157485962\n",
      "[29,   800] loss: 0.076228\n",
      "Learning rate:0.026616139146171464\n",
      "Accuracy of the network on the 3268 test sentences:86.07711138310893\n",
      "Saved checkpoint to:./imdb_net_learnable_pooling_sgd_lr_0.00599875_gamma_0.88_500_epochs_32_batch.pth\n",
      "Time elapsed for epoch:29 is:164.8605272769928\n",
      "[30,   800] loss: 0.073915\n",
      "Learning rate:0.025472337684644658\n",
      "Accuracy of the network on the 3268 test sentences:85.28151774785802\n",
      "Time elapsed for epoch:30 is:165.34471988677979\n",
      "[31,   800] loss: 0.058124\n",
      "Learning rate:0.02420280769538732\n",
      "Accuracy of the network on the 3268 test sentences:85.80171358629131\n",
      "Time elapsed for epoch:31 is:165.9862585067749\n",
      "[32,   800] loss: 0.050723\n",
      "Learning rate:0.022827570424710484\n",
      "Accuracy of the network on the 3268 test sentences:85.74051407588739\n",
      "Time elapsed for epoch:32 is:165.1439654827118\n",
      "[33,   800] loss: 0.040595\n",
      "Learning rate:0.02136831418589966\n",
      "Accuracy of the network on the 3268 test sentences:86.13831089351285\n",
      "Saved checkpoint to:./imdb_net_learnable_pooling_sgd_lr_0.00599875_gamma_0.88_500_epochs_32_batch.pth\n",
      "Time elapsed for epoch:33 is:165.29591846466064\n",
      "[34,   800] loss: 0.032363\n",
      "Learning rate:0.019848052321558306\n",
      "Accuracy of the network on the 3268 test sentences:84.36352509179926\n",
      "Time elapsed for epoch:34 is:172.02738499641418\n",
      "[35,   800] loss: 0.030013\n",
      "Learning rate:0.018290760269447516\n",
      "Accuracy of the network on the 3268 test sentences:86.47490820073439\n",
      "Saved checkpoint to:./imdb_net_learnable_pooling_sgd_lr_0.00599875_gamma_0.88_500_epochs_32_batch.pth\n",
      "Time elapsed for epoch:35 is:168.16939687728882\n",
      "[36,   800] loss: 0.022167\n",
      "Learning rate:0.016720997455510252\n",
      "Accuracy of the network on the 3268 test sentences:85.89351285189719\n",
      "Time elapsed for epoch:36 is:169.191650390625\n",
      "[37,   800] loss: 0.019164\n",
      "Learning rate:0.015163519977053154\n",
      "Accuracy of the network on the 3268 test sentences:86.65850673194615\n",
      "Saved checkpoint to:./imdb_net_learnable_pooling_sgd_lr_0.00599875_gamma_0.88_500_epochs_32_batch.pth\n",
      "Time elapsed for epoch:37 is:169.1347622871399\n",
      "[38,   800] loss: 0.012112\n",
      "Learning rate:0.013642890184303435\n",
      "Accuracy of the network on the 3268 test sentences:86.99510403916769\n",
      "Saved checkpoint to:./imdb_net_learnable_pooling_sgd_lr_0.00599875_gamma_0.88_500_epochs_32_batch.pth\n",
      "Time elapsed for epoch:38 is:167.97693252563477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39,   800] loss: 0.010791\n",
      "Learning rate:0.012183089317472973\n",
      "Accuracy of the network on the 3268 test sentences:87.02570379436965\n",
      "Saved checkpoint to:./imdb_net_learnable_pooling_sgd_lr_0.00599875_gamma_0.88_500_epochs_32_batch.pth\n",
      "Time elapsed for epoch:39 is:168.93146419525146\n",
      "[40,   800] loss: 0.007906\n",
      "Learning rate:0.010807139308274451\n",
      "Accuracy of the network on the 3268 test sentences:86.90330477356181\n",
      "Time elapsed for epoch:40 is:166.8956298828125\n",
      "[41,   800] loss: 0.006342\n",
      "Learning rate:0.009536739710305619\n",
      "Accuracy of the network on the 3268 test sentences:86.78090575275398\n",
      "Time elapsed for epoch:41 is:165.31841254234314\n",
      "[42,   800] loss: 0.005960\n",
      "Learning rate:0.008391925484126386\n",
      "Accuracy of the network on the 3268 test sentences:86.87270501835985\n",
      "Time elapsed for epoch:42 is:165.41787362098694\n",
      "[43,   800] loss: 0.004494\n",
      "Learning rate:0.007390751033962464\n",
      "Accuracy of the network on the 3268 test sentences:87.08690330477356\n",
      "Saved checkpoint to:./imdb_net_learnable_pooling_sgd_lr_0.00599875_gamma_0.88_500_epochs_32_batch.pth\n",
      "Time elapsed for epoch:43 is:167.94267296791077\n",
      "[44,   800] loss: 0.002625\n",
      "Learning rate:0.0065490054789655635\n",
      "Accuracy of the network on the 3268 test sentences:86.84210526315789\n",
      "Time elapsed for epoch:44 is:166.71793484687805\n",
      "[45,   800] loss: 0.002898\n",
      "Learning rate:0.00587996364937241\n",
      "Accuracy of the network on the 3268 test sentences:86.78090575275398\n",
      "Time elapsed for epoch:45 is:167.38943433761597\n",
      "[46,   800] loss: 0.003099\n",
      "Learning rate:0.005394176734501907\n",
      "Accuracy of the network on the 3268 test sentences:87.60709914320685\n",
      "Saved checkpoint to:./imdb_net_learnable_pooling_sgd_lr_0.00599875_gamma_0.88_500_epochs_32_batch.pth\n",
      "Time elapsed for epoch:46 is:169.1903715133667\n",
      "[47,   800] loss: 0.002559\n",
      "Learning rate:0.005099305884196594\n",
      "Accuracy of the network on the 3268 test sentences:87.48470012239902\n",
      "Time elapsed for epoch:47 is:165.64403295516968\n",
      "[48,   800] loss: 0.001385\n",
      "Learning rate:0.005000001387913093\n",
      "Accuracy of the network on the 3268 test sentences:86.87270501835985\n",
      "Time elapsed for epoch:48 is:164.98764181137085\n",
      "[49,   800] loss: 0.001728\n",
      "Learning rate:0.00585279\n",
      "Accuracy of the network on the 3268 test sentences:87.27050183598531\n",
      "Time elapsed for epoch:49 is:164.93704843521118\n",
      "[50,   800] loss: 0.001927\n",
      "Learning rate:0.00670879\n",
      "Accuracy of the network on the 3268 test sentences:87.30110159118728\n",
      "Time elapsed for epoch:50 is:164.90754103660583\n",
      "[51,   800] loss: 0.001807\n",
      "Learning rate:0.00756479\n",
      "Accuracy of the network on the 3268 test sentences:87.20930232558139\n",
      "Time elapsed for epoch:51 is:165.28107976913452\n",
      "[52,   800] loss: 0.003521\n",
      "Learning rate:0.00842079\n",
      "Accuracy of the network on the 3268 test sentences:87.36230110159119\n",
      "Time elapsed for epoch:52 is:165.44845366477966\n",
      "[53,   800] loss: 0.002358\n",
      "Learning rate:0.00927679\n",
      "Accuracy of the network on the 3268 test sentences:87.66829865361078\n",
      "Saved checkpoint to:./imdb_net_learnable_pooling_sgd_lr_0.00599875_gamma_0.88_500_epochs_32_batch.pth\n",
      "Time elapsed for epoch:53 is:165.6499366760254\n",
      "[54,   800] loss: 0.002236\n",
      "Learning rate:0.01013279\n",
      "Accuracy of the network on the 3268 test sentences:87.20930232558139\n",
      "Time elapsed for epoch:54 is:165.32939529418945\n",
      "[55,   800] loss: 0.004364\n",
      "Learning rate:0.01098879\n",
      "Accuracy of the network on the 3268 test sentences:87.30110159118728\n",
      "Time elapsed for epoch:55 is:164.85772109031677\n",
      "[56,   800] loss: 0.003442\n",
      "Learning rate:0.01184479\n",
      "Accuracy of the network on the 3268 test sentences:86.71970624235006\n",
      "Time elapsed for epoch:56 is:165.03254055976868\n",
      "[57,   800] loss: 0.005401\n",
      "Learning rate:0.01270079\n",
      "Accuracy of the network on the 3268 test sentences:86.75030599755202\n",
      "Time elapsed for epoch:57 is:165.61798453330994\n",
      "[58,   800] loss: 0.004837\n",
      "Learning rate:0.013556789999999999\n",
      "Accuracy of the network on the 3268 test sentences:87.30110159118728\n",
      "Time elapsed for epoch:58 is:165.2208650112152\n",
      "[59,   800] loss: 0.006222\n",
      "Learning rate:0.014412789999999998\n",
      "Accuracy of the network on the 3268 test sentences:86.41370869033048\n",
      "Time elapsed for epoch:59 is:167.6422152519226\n",
      "[60,   800] loss: 0.006905\n",
      "Learning rate:0.01526879\n",
      "Accuracy of the network on the 3268 test sentences:87.45410036719706\n",
      "Time elapsed for epoch:60 is:169.0246865749359\n",
      "[61,   800] loss: 0.007082\n",
      "Learning rate:0.01612479\n",
      "Accuracy of the network on the 3268 test sentences:86.81150550795594\n",
      "Time elapsed for epoch:61 is:166.24136877059937\n",
      "[62,   800] loss: 0.007418\n",
      "Learning rate:0.01698079\n",
      "Accuracy of the network on the 3268 test sentences:85.98531211750306\n",
      "Time elapsed for epoch:62 is:165.43819904327393\n",
      "[63,   800] loss: 0.009758\n",
      "Learning rate:0.017836789999999998\n",
      "Accuracy of the network on the 3268 test sentences:86.78090575275398\n",
      "Time elapsed for epoch:63 is:165.86196112632751\n",
      "[64,   800] loss: 0.012363\n",
      "Learning rate:0.01869279\n",
      "Accuracy of the network on the 3268 test sentences:86.01591187270502\n",
      "Time elapsed for epoch:64 is:165.7010235786438\n",
      "[65,   800] loss: 0.011767\n",
      "Learning rate:0.01954879\n",
      "Accuracy of the network on the 3268 test sentences:86.13831089351285\n",
      "Time elapsed for epoch:65 is:165.8610634803772\n",
      "[66,   800] loss: 0.013162\n",
      "Learning rate:0.02040479\n",
      "Accuracy of the network on the 3268 test sentences:86.07711138310893\n",
      "Time elapsed for epoch:66 is:165.1542410850525\n",
      "[67,   800] loss: 0.017046\n",
      "Learning rate:0.02126079\n",
      "Accuracy of the network on the 3268 test sentences:87.36230110159119\n",
      "Time elapsed for epoch:67 is:164.92434525489807\n",
      "[68,   800] loss: 0.021347\n",
      "Learning rate:0.02211679\n",
      "Accuracy of the network on the 3268 test sentences:86.87270501835985\n",
      "Time elapsed for epoch:68 is:166.0471215248108\n",
      "[69,   800] loss: 0.022244\n",
      "Learning rate:0.02297279\n",
      "Accuracy of the network on the 3268 test sentences:86.75030599755202\n",
      "Time elapsed for epoch:69 is:164.72417998313904\n",
      "[70,   800] loss: 0.024109\n",
      "Learning rate:0.02382879\n",
      "Accuracy of the network on the 3268 test sentences:86.78090575275398\n",
      "Time elapsed for epoch:70 is:164.69864749908447\n",
      "[71,   800] loss: 0.030623\n",
      "Learning rate:0.024684789999999998\n",
      "Accuracy of the network on the 3268 test sentences:87.36230110159119\n",
      "Time elapsed for epoch:71 is:164.97808742523193\n",
      "[72,   800] loss: 0.029126\n",
      "Learning rate:0.02554079\n",
      "Accuracy of the network on the 3268 test sentences:86.23011015911872\n",
      "Time elapsed for epoch:72 is:165.12570023536682\n",
      "[73,   800] loss: 0.030469\n",
      "Learning rate:0.02639679\n",
      "Accuracy of the network on the 3268 test sentences:85.89351285189719\n",
      "Time elapsed for epoch:73 is:165.11308693885803\n",
      "[74,   800] loss: 0.034177\n",
      "Learning rate:0.02631625808763121\n",
      "Accuracy of the network on the 3268 test sentences:85.43451652386781\n",
      "Time elapsed for epoch:74 is:164.49724316596985\n",
      "[75,   800] loss: 0.031336\n",
      "Learning rate:0.0260650926314289\n",
      "Accuracy of the network on the 3268 test sentences:85.49571603427172\n",
      "Time elapsed for epoch:75 is:165.28283643722534\n",
      "[76,   800] loss: 0.031069\n",
      "Learning rate:0.025650463472622745\n",
      "Accuracy of the network on the 3268 test sentences:85.43451652386781\n",
      "Time elapsed for epoch:76 is:165.50444340705872\n",
      "[77,   800] loss: 0.035907\n",
      "Learning rate:0.02507890956073458\n",
      "Accuracy of the network on the 3268 test sentences:86.68910648714811\n",
      "Time elapsed for epoch:77 is:164.98615670204163\n",
      "[78,   800] loss: 0.031833\n",
      "Learning rate:0.024359444642384622\n",
      "Accuracy of the network on the 3268 test sentences:86.47490820073439\n",
      "Time elapsed for epoch:78 is:164.88882088661194\n",
      "[79,   800] loss: 0.025024\n",
      "Learning rate:0.023503415109122773\n",
      "Accuracy of the network on the 3268 test sentences:85.18971848225215\n",
      "Time elapsed for epoch:79 is:164.5925579071045\n",
      "[80,   800] loss: 0.028885\n",
      "Learning rate:0.022524321058055827\n",
      "Accuracy of the network on the 3268 test sentences:85.5875152998776\n",
      "Time elapsed for epoch:80 is:164.53208231925964\n",
      "[81,   800] loss: 0.021936\n",
      "Learning rate:0.021437603387251546\n",
      "Accuracy of the network on the 3268 test sentences:85.9547123623011\n",
      "Time elapsed for epoch:81 is:164.3050138950348\n",
      "[82,   800] loss: 0.018662\n",
      "Learning rate:0.020260400283552173\n",
      "Accuracy of the network on the 3268 test sentences:86.10771113831089\n",
      "Time elapsed for epoch:82 is:164.44486331939697\n",
      "[83,   800] loss: 0.016766\n",
      "Learning rate:0.01901127694313011\n",
      "Accuracy of the network on the 3268 test sentences:86.71970624235006\n",
      "Time elapsed for epoch:83 is:164.3682141304016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84,   800] loss: 0.013832\n",
      "Learning rate:0.017709932787253913\n",
      "Accuracy of the network on the 3268 test sentences:85.83231334149326\n",
      "Time elapsed for epoch:84 is:164.5293517112732\n",
      "[85,   800] loss: 0.007551\n",
      "Learning rate:0.016376890790647074\n",
      "Accuracy of the network on the 3268 test sentences:86.10771113831089\n",
      "Time elapsed for epoch:85 is:164.78696012496948\n",
      "[86,   800] loss: 0.007889\n",
      "Learning rate:0.015033173821916778\n",
      "Accuracy of the network on the 3268 test sentences:85.70991432068543\n",
      "Time elapsed for epoch:86 is:165.16379284858704\n",
      "[87,   800] loss: 0.007032\n",
      "Learning rate:0.0136999731003575\n",
      "Accuracy of the network on the 3268 test sentences:86.81150550795594\n",
      "Time elapsed for epoch:87 is:165.81852650642395\n",
      "[88,   800] loss: 0.006086\n",
      "Learning rate:0.01239831399776374\n",
      "Accuracy of the network on the 3268 test sentences:86.44430844553244\n",
      "Time elapsed for epoch:88 is:165.0767629146576\n",
      "[89,   800] loss: 0.005363\n",
      "Learning rate:0.011148724455756865\n",
      "Accuracy of the network on the 3268 test sentences:86.93390452876378\n",
      "Time elapsed for epoch:89 is:165.0263319015503\n",
      "[90,   800] loss: 0.003410\n",
      "Learning rate:0.009970911247882932\n",
      "Accuracy of the network on the 3268 test sentences:87.11750305997552\n",
      "Time elapsed for epoch:90 is:165.3330466747284\n",
      "[91,   800] loss: 0.003529\n",
      "Learning rate:0.008883449192021609\n",
      "Accuracy of the network on the 3268 test sentences:86.71970624235006\n",
      "Time elapsed for epoch:91 is:165.08560156822205\n",
      "[92,   800] loss: 0.003515\n",
      "Learning rate:0.007903488214412186\n",
      "Accuracy of the network on the 3268 test sentences:86.68910648714811\n",
      "Time elapsed for epoch:92 is:165.1590883731842\n",
      "[93,   800] loss: 0.001628\n",
      "Learning rate:0.00704648288507187\n",
      "Accuracy of the network on the 3268 test sentences:86.59730722154222\n",
      "Time elapsed for epoch:93 is:164.93515706062317\n",
      "[94,   800] loss: 0.001753\n",
      "Learning rate:0.006325948689994523\n",
      "Accuracy of the network on the 3268 test sentences:86.50550795593635\n",
      "Time elapsed for epoch:94 is:164.6204056739807\n",
      "[95,   800] loss: 0.000972\n",
      "Learning rate:0.005753248883862783\n",
      "Accuracy of the network on the 3268 test sentences:87.36230110159119\n",
      "Time elapsed for epoch:95 is:164.6342055797577\n",
      "[96,   800] loss: 0.000504\n",
      "Learning rate:0.005337415284733632\n",
      "Accuracy of the network on the 3268 test sentences:86.93390452876378\n",
      "Time elapsed for epoch:96 is:164.99643921852112\n",
      "[97,   800] loss: 0.001870\n",
      "Learning rate:0.005085005836872284\n",
      "Accuracy of the network on the 3268 test sentences:87.48470012239902\n",
      "Time elapsed for epoch:97 is:165.06331634521484\n",
      "[98,   800] loss: 0.001614\n",
      "Learning rate:0.005000001188053608\n",
      "Accuracy of the network on the 3268 test sentences:87.79069767441861\n",
      "Saved checkpoint to:./imdb_net_learnable_pooling_sgd_lr_0.00599875_gamma_0.88_500_epochs_32_batch.pth\n",
      "Time elapsed for epoch:98 is:165.0423424243927\n",
      "[99,   800] loss: 0.000856\n",
      "Learning rate:0.0057265452\n",
      "Accuracy of the network on the 3268 test sentences:87.17870257037944\n",
      "Time elapsed for epoch:99 is:164.80243158340454\n",
      "[100,   800] loss: 0.001371\n",
      "Learning rate:0.0064558252\n",
      "Accuracy of the network on the 3268 test sentences:86.78090575275398\n",
      "Time elapsed for epoch:100 is:164.6319363117218\n",
      "[101,   800] loss: 0.000862\n",
      "Learning rate:0.0071851052\n",
      "Accuracy of the network on the 3268 test sentences:87.42350061199511\n",
      "Time elapsed for epoch:101 is:164.85545349121094\n",
      "[102,   800] loss: 0.000922\n",
      "Learning rate:0.007914385199999999\n",
      "Accuracy of the network on the 3268 test sentences:87.17870257037944\n",
      "Time elapsed for epoch:102 is:164.62233972549438\n",
      "[103,   800] loss: 0.001822\n",
      "Learning rate:0.0086436652\n",
      "Accuracy of the network on the 3268 test sentences:86.68910648714811\n",
      "Time elapsed for epoch:103 is:164.9201431274414\n",
      "[104,   800] loss: 0.001502\n",
      "Learning rate:0.0093729452\n",
      "Accuracy of the network on the 3268 test sentences:86.93390452876378\n",
      "Time elapsed for epoch:104 is:165.2561264038086\n",
      "[105,   800] loss: 0.001667\n",
      "Learning rate:0.010102225199999999\n",
      "Accuracy of the network on the 3268 test sentences:87.17870257037944\n",
      "Time elapsed for epoch:105 is:164.7670497894287\n",
      "[106,   800] loss: 0.000677\n",
      "Learning rate:0.0108315052\n",
      "Accuracy of the network on the 3268 test sentences:87.33170134638922\n",
      "Time elapsed for epoch:106 is:164.64918732643127\n",
      "[107,   800] loss: 0.001606\n",
      "Learning rate:0.0115607852\n",
      "Accuracy of the network on the 3268 test sentences:87.11750305997552\n",
      "Time elapsed for epoch:107 is:164.6847972869873\n",
      "[108,   800] loss: 0.000806\n",
      "Learning rate:0.012290065199999999\n",
      "Accuracy of the network on the 3268 test sentences:86.99510403916769\n",
      "Time elapsed for epoch:108 is:164.64298009872437\n",
      "[109,   800] loss: 0.003436\n",
      "Learning rate:0.0130193452\n",
      "Accuracy of the network on the 3268 test sentences:87.20930232558139\n",
      "Time elapsed for epoch:109 is:164.18820238113403\n",
      "[110,   800] loss: 0.001799\n",
      "Learning rate:0.0137486252\n",
      "Accuracy of the network on the 3268 test sentences:87.17870257037944\n",
      "Time elapsed for epoch:110 is:164.51961159706116\n",
      "[111,   800] loss: 0.003283\n",
      "Learning rate:0.014477905199999998\n",
      "Accuracy of the network on the 3268 test sentences:86.96450428396572\n",
      "Time elapsed for epoch:111 is:164.82869267463684\n",
      "[112,   800] loss: 0.003543\n",
      "Learning rate:0.0152071852\n",
      "Accuracy of the network on the 3268 test sentences:86.38310893512852\n",
      "Time elapsed for epoch:112 is:164.34538769721985\n",
      "[113,   800] loss: 0.003188\n",
      "Learning rate:0.0159364652\n",
      "Accuracy of the network on the 3268 test sentences:86.10771113831089\n",
      "Time elapsed for epoch:113 is:164.8182270526886\n",
      "[114,   800] loss: 0.004241\n",
      "Learning rate:0.0166657452\n",
      "Accuracy of the network on the 3268 test sentences:86.93390452876378\n",
      "Time elapsed for epoch:114 is:165.22684168815613\n",
      "[115,   800] loss: 0.005235\n",
      "Learning rate:0.0173950252\n",
      "Accuracy of the network on the 3268 test sentences:86.62790697674419\n",
      "Time elapsed for epoch:115 is:164.7672324180603\n",
      "[116,   800] loss: 0.003974\n",
      "Learning rate:0.0181243052\n",
      "Accuracy of the network on the 3268 test sentences:87.08690330477356\n",
      "Time elapsed for epoch:116 is:164.78580379486084\n",
      "[117,   800] loss: 0.006156\n",
      "Learning rate:0.0188535852\n",
      "Accuracy of the network on the 3268 test sentences:86.59730722154222\n",
      "Time elapsed for epoch:117 is:164.72287583351135\n",
      "[118,   800] loss: 0.008410\n",
      "Learning rate:0.019582865199999997\n",
      "Accuracy of the network on the 3268 test sentences:86.90330477356181\n",
      "Time elapsed for epoch:118 is:164.32091665267944\n",
      "[119,   800] loss: 0.009918\n",
      "Learning rate:0.0203121452\n",
      "Accuracy of the network on the 3268 test sentences:85.40391676866585\n",
      "Time elapsed for epoch:119 is:164.23477959632874\n",
      "[120,   800] loss: 0.010686\n",
      "Learning rate:0.021041425199999998\n",
      "Accuracy of the network on the 3268 test sentences:87.08690330477356\n",
      "Time elapsed for epoch:120 is:164.20883584022522\n",
      "[121,   800] loss: 0.011922\n",
      "Learning rate:0.021770705199999997\n",
      "Accuracy of the network on the 3268 test sentences:86.56670746634028\n",
      "Time elapsed for epoch:121 is:164.71523785591125\n",
      "[122,   800] loss: 0.012110\n",
      "Learning rate:0.0224999852\n",
      "Accuracy of the network on the 3268 test sentences:85.89351285189719\n",
      "Time elapsed for epoch:122 is:164.8625705242157\n",
      "[123,   800] loss: 0.010321\n",
      "Learning rate:0.023229265199999998\n",
      "Accuracy of the network on the 3268 test sentences:85.49571603427172\n",
      "Time elapsed for epoch:123 is:165.10856080055237\n",
      "[124,   800] loss: 0.013709\n",
      "Learning rate:0.023160655021200568\n",
      "Accuracy of the network on the 3268 test sentences:86.59730722154222\n",
      "Time elapsed for epoch:124 is:164.2745544910431\n",
      "[125,   800] loss: 0.013501\n",
      "Learning rate:0.022946671441879053\n",
      "Accuracy of the network on the 3268 test sentences:86.47490820073439\n",
      "Time elapsed for epoch:125 is:164.10602474212646\n",
      "[126,   800] loss: 0.014767\n",
      "Learning rate:0.022593422898731678\n",
      "Accuracy of the network on the 3268 test sentences:85.74051407588739\n",
      "Time elapsed for epoch:126 is:164.3309576511383\n",
      "[127,   800] loss: 0.009940\n",
      "Learning rate:0.022106480332304338\n",
      "Accuracy of the network on the 3268 test sentences:86.41370869033048\n",
      "Time elapsed for epoch:127 is:164.15357494354248\n",
      "[128,   800] loss: 0.015896\n",
      "Learning rate:0.021493523117754973\n",
      "Accuracy of the network on the 3268 test sentences:85.00611995104039\n",
      "Time elapsed for epoch:128 is:164.7990276813507\n",
      "[129,   800] loss: 0.010911\n",
      "Learning rate:0.020764217956519924\n",
      "Accuracy of the network on the 3268 test sentences:87.08690330477356\n",
      "Time elapsed for epoch:129 is:164.58901143074036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[130,   800] loss: 0.009854\n",
      "Learning rate:0.019930066426657657\n",
      "Accuracy of the network on the 3268 test sentences:85.77111383108935\n",
      "Time elapsed for epoch:130 is:164.21551084518433\n",
      "[131,   800] loss: 0.010185\n",
      "Learning rate:0.019004223596092062\n",
      "Accuracy of the network on the 3268 test sentences:86.78090575275398\n",
      "Time elapsed for epoch:131 is:164.59310817718506\n",
      "[132,   800] loss: 0.008185\n",
      "Learning rate:0.01800129055933286\n",
      "Accuracy of the network on the 3268 test sentences:86.75030599755202\n",
      "Time elapsed for epoch:132 is:164.8053252696991\n",
      "[133,   800] loss: 0.008625\n",
      "Learning rate:0.016937084169492904\n",
      "Accuracy of the network on the 3268 test sentences:86.59730722154222\n",
      "Time elapsed for epoch:133 is:164.64333176612854\n",
      "[134,   800] loss: 0.008160\n",
      "Learning rate:0.015828387597066042\n",
      "Accuracy of the network on the 3268 test sentences:86.81150550795594\n",
      "Time elapsed for epoch:134 is:164.71956491470337\n",
      "[135,   800] loss: 0.005647\n",
      "Learning rate:0.014692685649302685\n",
      "Accuracy of the network on the 3268 test sentences:87.08690330477356\n",
      "Time elapsed for epoch:135 is:165.57650136947632\n",
      "[136,   800] loss: 0.005269\n",
      "Learning rate:0.013547889024354519\n",
      "Accuracy of the network on the 3268 test sentences:87.30110159118728\n",
      "Time elapsed for epoch:136 is:164.586758852005\n",
      "[137,   800] loss: 0.003838\n",
      "Learning rate:0.012412051848865326\n",
      "Accuracy of the network on the 3268 test sentences:87.17870257037944\n",
      "Time elapsed for epoch:137 is:164.76155471801758\n",
      "[138,   800] loss: 0.002519\n",
      "Learning rate:0.01130308695360881\n",
      "Accuracy of the network on the 3268 test sentences:87.11750305997552\n",
      "Time elapsed for epoch:138 is:164.70732045173645\n",
      "[139,   800] loss: 0.002136\n",
      "Learning rate:0.010238483377446688\n",
      "Accuracy of the network on the 3268 test sentences:86.90330477356181\n",
      "Time elapsed for epoch:139 is:165.2305109500885\n",
      "[140,   800] loss: 0.002873\n",
      "Learning rate:0.009235030554738392\n",
      "Accuracy of the network on the 3268 test sentences:87.05630354957161\n",
      "Time elapsed for epoch:140 is:165.38679552078247\n",
      "[141,   800] loss: 0.002367\n",
      "Learning rate:0.00830855353593168\n",
      "Accuracy of the network on the 3268 test sentences:87.02570379436965\n",
      "Time elapsed for epoch:141 is:165.63930296897888\n",
      "[142,   800] loss: 0.001527\n",
      "Learning rate:0.007473663417063691\n",
      "Accuracy of the network on the 3268 test sentences:87.08690330477356\n",
      "Time elapsed for epoch:142 is:165.25894975662231\n",
      "[143,   800] loss: 0.001245\n",
      "Learning rate:0.006743526914048146\n",
      "Accuracy of the network on the 3268 test sentences:86.99510403916769\n",
      "Time elapsed for epoch:143 is:165.60796737670898\n",
      "[144,   800] loss: 0.001354\n",
      "Learning rate:0.006129658715700006\n",
      "Accuracy of the network on the 3268 test sentences:86.96450428396572\n",
      "Time elapsed for epoch:144 is:165.24720811843872\n",
      "[145,   800] loss: 0.001609\n",
      "Learning rate:0.005641739890214312\n",
      "Accuracy of the network on the 3268 test sentences:87.08690330477356\n",
      "Time elapsed for epoch:145 is:164.77199912071228\n",
      "[146,   800] loss: 0.000466\n",
      "Learning rate:0.00528746520893755\n",
      "Accuracy of the network on the 3268 test sentences:87.36230110159119\n",
      "Time elapsed for epoch:146 is:166.45731663703918\n",
      "[147,   800] loss: 0.000720\n",
      "Learning rate:0.005072421795226892\n",
      "Accuracy of the network on the 3268 test sentences:86.81150550795594\n",
      "Time elapsed for epoch:147 is:168.2093403339386\n",
      "[148,   800] loss: 0.000474\n",
      "Learning rate:0.0050000010121772605\n",
      "Accuracy of the network on the 3268 test sentences:87.66829865361078\n",
      "Time elapsed for epoch:148 is:167.31993532180786\n",
      "[149,   800] loss: 0.000579\n",
      "Learning rate:0.005615449776\n",
      "Accuracy of the network on the 3268 test sentences:87.57649938800489\n",
      "Time elapsed for epoch:149 is:167.12994027137756\n",
      "[150,   800] loss: 0.000389\n",
      "Learning rate:0.006233216176\n",
      "Accuracy of the network on the 3268 test sentences:87.57649938800489\n",
      "Time elapsed for epoch:150 is:165.5703146457672\n",
      "[151,   800] loss: 0.000635\n",
      "Learning rate:0.006850982576\n",
      "Accuracy of the network on the 3268 test sentences:86.99510403916769\n",
      "Time elapsed for epoch:151 is:165.45794296264648\n",
      "[152,   800] loss: 0.001516\n",
      "Learning rate:0.007468748976\n",
      "Accuracy of the network on the 3268 test sentences:87.60709914320685\n",
      "Time elapsed for epoch:152 is:165.29449272155762\n",
      "[153,   800] loss: 0.000827\n",
      "Learning rate:0.008086515376000001\n",
      "Accuracy of the network on the 3268 test sentences:87.20930232558139\n",
      "Time elapsed for epoch:153 is:165.1291537284851\n",
      "[154,   800] loss: 0.001264\n",
      "Learning rate:0.008704281776\n",
      "Accuracy of the network on the 3268 test sentences:86.56670746634028\n",
      "Time elapsed for epoch:154 is:165.04152655601501\n",
      "[155,   800] loss: 0.001135\n",
      "Learning rate:0.009322048175999999\n",
      "Accuracy of the network on the 3268 test sentences:86.78090575275398\n",
      "Time elapsed for epoch:155 is:165.25396823883057\n",
      "[156,   800] loss: 0.000893\n",
      "Learning rate:0.009939814576\n",
      "Accuracy of the network on the 3268 test sentences:87.17870257037944\n",
      "Time elapsed for epoch:156 is:165.67502093315125\n",
      "[157,   800] loss: 0.000439\n",
      "Learning rate:0.010557580976\n",
      "Accuracy of the network on the 3268 test sentences:86.99510403916769\n",
      "Time elapsed for epoch:157 is:165.7545726299286\n",
      "[158,   800] loss: 0.000819\n",
      "Learning rate:0.011175347375999999\n",
      "Accuracy of the network on the 3268 test sentences:87.39290085679315\n",
      "Time elapsed for epoch:158 is:165.1294903755188\n",
      "[159,   800] loss: 0.000783\n",
      "Learning rate:0.011793113776\n",
      "Accuracy of the network on the 3268 test sentences:87.42350061199511\n",
      "Time elapsed for epoch:159 is:165.14580917358398\n",
      "[160,   800] loss: 0.000929\n",
      "Learning rate:0.012410880175999998\n",
      "Accuracy of the network on the 3268 test sentences:87.17870257037944\n",
      "Time elapsed for epoch:160 is:165.13925194740295\n",
      "[161,   800] loss: 0.000628\n",
      "Learning rate:0.013028646575999999\n",
      "Accuracy of the network on the 3268 test sentences:86.96450428396572\n",
      "Time elapsed for epoch:161 is:165.05428814888\n",
      "[162,   800] loss: 0.002114\n",
      "Learning rate:0.013646412976\n",
      "Accuracy of the network on the 3268 test sentences:87.45410036719706\n",
      "Time elapsed for epoch:162 is:164.6717460155487\n",
      "[163,   800] loss: 0.002149\n",
      "Learning rate:0.014264179375999997\n",
      "Accuracy of the network on the 3268 test sentences:86.01591187270502\n",
      "Time elapsed for epoch:163 is:164.7512264251709\n",
      "[164,   800] loss: 0.004055\n",
      "Learning rate:0.014881945776000001\n",
      "Accuracy of the network on the 3268 test sentences:86.78090575275398\n",
      "Time elapsed for epoch:164 is:164.99329161643982\n",
      "[165,   800] loss: 0.002707\n",
      "Learning rate:0.015499712175999998\n",
      "Accuracy of the network on the 3268 test sentences:86.84210526315789\n",
      "Time elapsed for epoch:165 is:165.1366903781891\n",
      "[166,   800] loss: 0.002933\n",
      "Learning rate:0.016117478576\n",
      "Accuracy of the network on the 3268 test sentences:86.93390452876378\n",
      "Time elapsed for epoch:166 is:165.0502336025238\n",
      "[167,   800] loss: 0.004480\n",
      "Learning rate:0.016735244976\n",
      "Accuracy of the network on the 3268 test sentences:87.30110159118728\n",
      "Time elapsed for epoch:167 is:164.66773867607117\n",
      "[168,   800] loss: 0.003803\n",
      "Learning rate:0.017353011376\n",
      "Accuracy of the network on the 3268 test sentences:87.05630354957161\n",
      "Time elapsed for epoch:168 is:164.56057453155518\n",
      "[169,   800] loss: 0.003238\n",
      "Learning rate:0.017970777776\n",
      "Accuracy of the network on the 3268 test sentences:86.29130966952265\n",
      "Time elapsed for epoch:169 is:164.03390836715698\n",
      "[170,   800] loss: 0.004290\n",
      "Learning rate:0.018588544175999998\n",
      "Accuracy of the network on the 3268 test sentences:86.84210526315789\n",
      "Time elapsed for epoch:170 is:164.32847499847412\n",
      "[171,   800] loss: 0.004374\n",
      "Learning rate:0.019206310576\n",
      "Accuracy of the network on the 3268 test sentences:86.65850673194615\n",
      "Time elapsed for epoch:171 is:164.78088068962097\n",
      "[172,   800] loss: 0.007373\n",
      "Learning rate:0.019824076976\n",
      "Accuracy of the network on the 3268 test sentences:86.44430844553244\n",
      "Time elapsed for epoch:172 is:164.65829133987427\n",
      "[173,   800] loss: 0.006088\n",
      "Learning rate:0.020441843375999996\n",
      "Accuracy of the network on the 3268 test sentences:86.71970624235006\n",
      "Time elapsed for epoch:173 is:165.02406787872314\n",
      "[174,   800] loss: 0.006422\n",
      "Learning rate:0.020383724322741607\n",
      "Accuracy of the network on the 3268 test sentences:86.65850673194615\n",
      "Time elapsed for epoch:174 is:164.93130564689636\n",
      "[175,   800] loss: 0.007076\n",
      "Learning rate:0.020202460795075185\n",
      "Accuracy of the network on the 3268 test sentences:87.02570379436965\n",
      "Time elapsed for epoch:175 is:164.88878059387207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[176,   800] loss: 0.007194\n",
      "Learning rate:0.019903227193707535\n",
      "Accuracy of the network on the 3268 test sentences:86.29130966952265\n",
      "Time elapsed for epoch:176 is:164.47524905204773\n",
      "[177,   800] loss: 0.005587\n",
      "Learning rate:0.019490742611285725\n",
      "Accuracy of the network on the 3268 test sentences:86.81150550795594\n",
      "Time elapsed for epoch:177 is:164.91408514976501\n",
      "[178,   800] loss: 0.007794\n",
      "Learning rate:0.018971512176080882\n",
      "Accuracy of the network on the 3268 test sentences:85.86291309669522\n",
      "Time elapsed for epoch:178 is:164.46286964416504\n",
      "[179,   800] loss: 0.006041\n",
      "Learning rate:0.01835372446222942\n",
      "Accuracy of the network on the 3268 test sentences:86.16891064871481\n",
      "Time elapsed for epoch:179 is:164.608957529068\n",
      "[180,   800] loss: 0.005458\n",
      "Learning rate:0.017647122351027264\n",
      "Accuracy of the network on the 3268 test sentences:86.65850673194615\n",
      "Time elapsed for epoch:180 is:164.537371635437\n",
      "[181,   800] loss: 0.004069\n",
      "Learning rate:0.01686284937987172\n",
      "Accuracy of the network on the 3268 test sentences:86.44430844553244\n",
      "Time elapsed for epoch:181 is:165.3534061908722\n",
      "[182,   800] loss: 0.006721\n",
      "Learning rate:0.016013274002019864\n",
      "Accuracy of the network on the 3268 test sentences:86.84210526315789\n",
      "Time elapsed for epoch:182 is:165.067298412323\n",
      "[183,   800] loss: 0.003839\n",
      "Learning rate:0.015111794528692164\n",
      "Accuracy of the network on the 3268 test sentences:86.87270501835985\n",
      "Time elapsed for epoch:183 is:164.58425974845886\n",
      "[184,   800] loss: 0.002976\n",
      "Learning rate:0.014172627829700718\n",
      "Accuracy of the network on the 3268 test sentences:86.90330477356181\n",
      "Time elapsed for epoch:184 is:165.0416977405548\n",
      "[185,   800] loss: 0.004014\n",
      "Learning rate:0.013210585124919624\n",
      "Accuracy of the network on the 3268 test sentences:87.14810281517748\n",
      "Time elapsed for epoch:185 is:164.80457401275635\n",
      "[186,   800] loss: 0.002605\n",
      "Learning rate:0.012240838402499728\n",
      "Accuracy of the network on the 3268 test sentences:87.54589963280294\n",
      "Time elapsed for epoch:186 is:164.80846691131592\n",
      "[187,   800] loss: 0.002007\n",
      "Learning rate:0.011278681147552209\n",
      "Accuracy of the network on the 3268 test sentences:86.78090575275398\n",
      "Time elapsed for epoch:187 is:165.0041389465332\n",
      "[188,   800] loss: 0.001798\n",
      "Learning rate:0.01033928715475247\n",
      "Accuracy of the network on the 3268 test sentences:87.88249694002448\n",
      "Saved checkpoint to:./imdb_net_learnable_pooling_sgd_lr_0.00599875_gamma_0.88_500_epochs_32_batch.pth\n",
      "Time elapsed for epoch:188 is:165.3206169605255\n",
      "[189,   800] loss: 0.001287\n",
      "Learning rate:0.009437471228533735\n",
      "Accuracy of the network on the 3268 test sentences:87.23990208078335\n",
      "Time elapsed for epoch:189 is:165.0765995979309\n",
      "[190,   800] loss: 0.001259\n",
      "Learning rate:0.008587455544771198\n",
      "Accuracy of the network on the 3268 test sentences:87.48470012239902\n",
      "Time elapsed for epoch:190 is:165.55418634414673\n",
      "[191,   800] loss: 0.001462\n",
      "Learning rate:0.0078026453585725445\n",
      "Accuracy of the network on the 3268 test sentences:87.45410036719706\n",
      "Time elapsed for epoch:191 is:165.2171173095703\n",
      "[192,   800] loss: 0.000720\n",
      "Learning rate:0.007095417595397014\n",
      "Accuracy of the network on the 3268 test sentences:87.85189718482252\n",
      "Time elapsed for epoch:192 is:165.11629700660706\n",
      "[193,   800] loss: 0.001000\n",
      "Learning rate:0.006476925659547269\n",
      "Accuracy of the network on the 3268 test sentences:87.33170134638922\n",
      "Time elapsed for epoch:193 is:164.99365639686584\n",
      "[194,   800] loss: 0.000608\n",
      "Learning rate:0.005956923538320832\n",
      "Accuracy of the network on the 3268 test sentences:87.63769889840881\n",
      "Time elapsed for epoch:194 is:164.77468276023865\n",
      "[195,   800] loss: 0.000789\n",
      "Learning rate:0.005543611975803656\n",
      "Accuracy of the network on the 3268 test sentences:87.42350061199511\n",
      "Time elapsed for epoch:195 is:164.71943187713623\n",
      "[196,   800] loss: 0.000424\n",
      "Learning rate:0.005243509142236999\n",
      "Accuracy of the network on the 3268 test sentences:87.48470012239902\n",
      "Time elapsed for epoch:196 is:164.37408065795898\n",
      "[197,   800] loss: 0.000480\n",
      "Learning rate:0.005061347838578947\n",
      "Accuracy of the network on the 3268 test sentences:87.48470012239902\n",
      "Time elapsed for epoch:197 is:165.02849674224854\n",
      "[198,   800] loss: 0.000530\n",
      "Learning rate:0.005000000857406075\n",
      "Accuracy of the network on the 3268 test sentences:87.60709914320685\n",
      "Time elapsed for epoch:198 is:164.81865549087524\n",
      "[199,   800] loss: 0.000308\n",
      "Learning rate:0.00551768580288\n",
      "Accuracy of the network on the 3268 test sentences:87.88249694002448\n",
      "Time elapsed for epoch:199 is:164.98453950881958\n",
      "[200,   800] loss: 0.000198\n",
      "Learning rate:0.00603732023488\n",
      "Accuracy of the network on the 3268 test sentences:87.36230110159119\n",
      "Time elapsed for epoch:200 is:164.99895763397217\n",
      "[201,   800] loss: 0.000302\n",
      "Learning rate:0.00655695466688\n",
      "Accuracy of the network on the 3268 test sentences:87.79069767441861\n",
      "Time elapsed for epoch:201 is:164.9415566921234\n",
      "[202,   800] loss: 0.000195\n",
      "Learning rate:0.00707658909888\n",
      "Accuracy of the network on the 3268 test sentences:87.79069767441861\n",
      "Time elapsed for epoch:202 is:165.12477374076843\n",
      "[203,   800] loss: 0.000997\n",
      "Learning rate:0.007596223530880001\n",
      "Accuracy of the network on the 3268 test sentences:87.76009791921665\n",
      "Time elapsed for epoch:203 is:164.76895570755005\n",
      "[204,   800] loss: 0.001045\n",
      "Learning rate:0.00811585796288\n",
      "Accuracy of the network on the 3268 test sentences:87.33170134638922\n",
      "Time elapsed for epoch:204 is:164.7713975906372\n",
      "[205,   800] loss: 0.000726\n",
      "Learning rate:0.00863549239488\n",
      "Accuracy of the network on the 3268 test sentences:87.72949816401469\n",
      "Time elapsed for epoch:205 is:165.24293518066406\n",
      "[206,   800] loss: 0.000328\n",
      "Learning rate:0.009155126826880002\n",
      "Accuracy of the network on the 3268 test sentences:87.33170134638922\n",
      "Time elapsed for epoch:206 is:165.14475178718567\n",
      "[207,   800] loss: 0.001115\n",
      "Learning rate:0.009674761258880001\n",
      "Accuracy of the network on the 3268 test sentences:87.39290085679315\n",
      "Time elapsed for epoch:207 is:165.01710629463196\n",
      "[208,   800] loss: 0.000916\n",
      "Learning rate:0.010194395690880001\n",
      "Accuracy of the network on the 3268 test sentences:87.05630354957161\n",
      "Time elapsed for epoch:208 is:164.93992257118225\n",
      "[209,   800] loss: 0.000319\n",
      "Learning rate:0.01071403012288\n",
      "Accuracy of the network on the 3268 test sentences:87.82129742962056\n",
      "Time elapsed for epoch:209 is:164.72649598121643\n",
      "[210,   800] loss: 0.000835\n",
      "Learning rate:0.01123366455488\n",
      "Accuracy of the network on the 3268 test sentences:87.27050183598531\n",
      "Time elapsed for epoch:210 is:164.93752241134644\n",
      "[211,   800] loss: 0.001146\n",
      "Learning rate:0.01175329898688\n",
      "Accuracy of the network on the 3268 test sentences:86.29130966952265\n",
      "Time elapsed for epoch:211 is:165.0110366344452\n",
      "[212,   800] loss: 0.001622\n",
      "Learning rate:0.01227293341888\n",
      "Accuracy of the network on the 3268 test sentences:87.20930232558139\n",
      "Time elapsed for epoch:212 is:164.99009037017822\n",
      "[213,   800] loss: 0.000881\n",
      "Learning rate:0.01279256785088\n",
      "Accuracy of the network on the 3268 test sentences:87.48470012239902\n",
      "Time elapsed for epoch:213 is:165.03798627853394\n",
      "[214,   800] loss: 0.001481\n",
      "Learning rate:0.01331220228288\n",
      "Accuracy of the network on the 3268 test sentences:86.78090575275398\n",
      "Time elapsed for epoch:214 is:164.8291916847229\n",
      "[215,   800] loss: 0.000681\n",
      "Learning rate:0.013831836714880003\n",
      "Accuracy of the network on the 3268 test sentences:86.93390452876378\n",
      "Time elapsed for epoch:215 is:164.4819040298462\n",
      "[216,   800] loss: 0.001158\n",
      "Learning rate:0.014351471146879999\n",
      "Accuracy of the network on the 3268 test sentences:86.44430844553244\n",
      "Time elapsed for epoch:216 is:164.6643044948578\n",
      "[217,   800] loss: 0.002090\n",
      "Learning rate:0.014871105578879999\n",
      "Accuracy of the network on the 3268 test sentences:86.96450428396572\n",
      "Time elapsed for epoch:217 is:164.8230152130127\n",
      "[218,   800] loss: 0.001300\n",
      "Learning rate:0.015390740010880002\n",
      "Accuracy of the network on the 3268 test sentences:86.81150550795594\n",
      "Time elapsed for epoch:218 is:164.61522817611694\n",
      "[219,   800] loss: 0.002754\n",
      "Learning rate:0.01591037444288\n",
      "Accuracy of the network on the 3268 test sentences:86.90330477356181\n",
      "Time elapsed for epoch:219 is:164.7496132850647\n",
      "[220,   800] loss: 0.002048\n",
      "Learning rate:0.01643000887488\n",
      "Accuracy of the network on the 3268 test sentences:86.87270501835985\n",
      "Time elapsed for epoch:220 is:164.91097402572632\n",
      "[221,   800] loss: 0.001105\n",
      "Learning rate:0.01694964330688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 3268 test sentences:87.23990208078335\n",
      "Time elapsed for epoch:221 is:165.50532150268555\n",
      "[222,   800] loss: 0.001786\n",
      "Learning rate:0.01746927773888\n",
      "Accuracy of the network on the 3268 test sentences:86.59730722154222\n",
      "Time elapsed for epoch:222 is:165.225923538208\n",
      "[223,   800] loss: 0.004101\n",
      "Learning rate:0.01798891217088\n",
      "Accuracy of the network on the 3268 test sentences:86.99510403916769\n",
      "Time elapsed for epoch:223 is:164.69884991645813\n",
      "[224,   800] loss: 0.005005\n",
      "Learning rate:0.017940025308097723\n",
      "Accuracy of the network on the 3268 test sentences:86.35250917992656\n",
      "Time elapsed for epoch:224 is:164.648859500885\n",
      "[225,   800] loss: 0.002850\n",
      "Learning rate:0.017787555425887783\n",
      "Accuracy of the network on the 3268 test sentences:87.08690330477356\n",
      "Time elapsed for epoch:225 is:164.48908686637878\n",
      "[226,   800] loss: 0.003929\n",
      "Learning rate:0.017535854973286295\n",
      "Accuracy of the network on the 3268 test sentences:86.44430844553244\n",
      "Time elapsed for epoch:226 is:164.43885707855225\n",
      "[227,   800] loss: 0.003637\n",
      "Learning rate:0.01718889341678935\n",
      "Accuracy of the network on the 3268 test sentences:87.48470012239902\n",
      "Time elapsed for epoch:227 is:164.82875275611877\n",
      "[228,   800] loss: 0.002591\n",
      "Learning rate:0.016752142547407683\n",
      "Accuracy of the network on the 3268 test sentences:86.62790697674419\n",
      "Time elapsed for epoch:228 is:164.96993279457092\n",
      "[229,   800] loss: 0.002476\n",
      "Learning rate:0.016232490187253774\n",
      "Accuracy of the network on the 3268 test sentences:86.75030599755202\n",
      "Time elapsed for epoch:229 is:165.20265007019043\n",
      "[230,   800] loss: 0.002547\n",
      "Learning rate:0.015638131564472524\n",
      "Accuracy of the network on the 3268 test sentences:86.41370869033048\n",
      "Time elapsed for epoch:230 is:165.1387276649475\n",
      "[231,   800] loss: 0.003736\n",
      "Learning rate:0.01497844006959782\n",
      "Accuracy of the network on the 3268 test sentences:86.16891064871481\n",
      "Time elapsed for epoch:231 is:164.65037655830383\n",
      "[232,   800] loss: 0.003335\n",
      "Learning rate:0.014263819431584432\n",
      "Accuracy of the network on the 3268 test sentences:86.93390452876378\n",
      "Time elapsed for epoch:232 is:164.68383741378784\n",
      "[233,   800] loss: 0.002304\n",
      "Learning rate:0.013505539644787512\n",
      "Accuracy of the network on the 3268 test sentences:87.63769889840881\n",
      "Time elapsed for epoch:233 is:164.81560802459717\n",
      "[234,   800] loss: 0.003029\n",
      "Learning rate:0.012715559234419232\n",
      "Accuracy of the network on the 3268 test sentences:87.02570379436965\n",
      "Time elapsed for epoch:234 is:164.60897874832153\n",
      "[235,   800] loss: 0.000943\n",
      "Learning rate:0.011906336663462528\n",
      "Accuracy of the network on the 3268 test sentences:87.20930232558139\n",
      "Time elapsed for epoch:235 is:164.827654838562\n",
      "[236,   800] loss: 0.001478\n",
      "Learning rate:0.011090633855267516\n",
      "Accuracy of the network on the 3268 test sentences:87.54589963280294\n",
      "Time elapsed for epoch:236 is:165.43398571014404\n",
      "[237,   800] loss: 0.001325\n",
      "Learning rate:0.01028131493039667\n",
      "Accuracy of the network on the 3268 test sentences:87.72949816401469\n",
      "Time elapsed for epoch:237 is:165.01982522010803\n",
      "[238,   800] loss: 0.000782\n",
      "Learning rate:0.009491143331758892\n",
      "Accuracy of the network on the 3268 test sentences:87.85189718482252\n",
      "Time elapsed for epoch:238 is:164.5988290309906\n",
      "[239,   800] loss: 0.001498\n",
      "Learning rate:0.008732580537490335\n",
      "Accuracy of the network on the 3268 test sentences:86.65850673194615\n",
      "Time elapsed for epoch:239 is:164.7731773853302\n",
      "[240,   800] loss: 0.000866\n",
      "Learning rate:0.008017589536000068\n",
      "Accuracy of the network on the 3268 test sentences:86.59730722154222\n",
      "Time elapsed for epoch:240 is:164.88608288764954\n",
      "[241,   800] loss: 0.001201\n",
      "Learning rate:0.007357446162496504\n",
      "Accuracy of the network on the 3268 test sentences:86.56670746634028\n",
      "Time elapsed for epoch:241 is:164.84950733184814\n",
      "[242,   800] loss: 0.000517\n",
      "Learning rate:0.00676256127233034\n",
      "Accuracy of the network on the 3268 test sentences:86.78090575275398\n",
      "Time elapsed for epoch:242 is:164.555006980896\n",
      "[243,   800] loss: 0.000293\n",
      "Learning rate:0.006242316555586498\n",
      "Accuracy of the network on the 3268 test sentences:87.30110159118728\n",
      "Time elapsed for epoch:243 is:164.92525577545166\n",
      "[244,   800] loss: 0.000484\n",
      "Learning rate:0.005804916582227159\n",
      "Accuracy of the network on the 3268 test sentences:87.33170134638922\n",
      "Time elapsed for epoch:244 is:165.31482338905334\n",
      "[245,   800] loss: 0.000448\n",
      "Learning rate:0.005457259411122279\n",
      "Accuracy of the network on the 3268 test sentences:87.27050183598531\n",
      "Time elapsed for epoch:245 is:164.70366668701172\n",
      "[246,   800] loss: 0.000244\n",
      "Learning rate:0.005204827803540513\n",
      "Accuracy of the network on the 3268 test sentences:86.90330477356181\n",
      "Time elapsed for epoch:246 is:164.56246781349182\n",
      "[247,   800] loss: 0.000204\n",
      "Learning rate:0.005051602756728755\n",
      "Accuracy of the network on the 3268 test sentences:87.45410036719706\n",
      "Time elapsed for epoch:247 is:164.4506266117096\n",
      "[248,   800] loss: 0.000126\n",
      "Learning rate:0.0050000007212074316\n",
      "Accuracy of the network on the 3268 test sentences:87.42350061199511\n",
      "Time elapsed for epoch:248 is:164.69525957107544\n",
      "[249,   800] loss: 0.000602\n",
      "Learning rate:0.0054316535065344\n",
      "Accuracy of the network on the 3268 test sentences:87.45410036719706\n",
      "Time elapsed for epoch:249 is:164.6124677658081\n",
      "[250,   800] loss: 0.000486\n",
      "Learning rate:0.0058649318066944\n",
      "Accuracy of the network on the 3268 test sentences:87.30110159118728\n",
      "Time elapsed for epoch:250 is:164.80221223831177\n",
      "[251,   800] loss: 0.000385\n",
      "Learning rate:0.0062982101068544\n",
      "Accuracy of the network on the 3268 test sentences:86.99510403916769\n",
      "Time elapsed for epoch:251 is:165.15830039978027\n",
      "[252,   800] loss: 0.000516\n",
      "Learning rate:0.0067314884070143995\n",
      "Accuracy of the network on the 3268 test sentences:87.88249694002448\n",
      "Time elapsed for epoch:252 is:165.7662570476532\n",
      "[253,   800] loss: 0.000645\n",
      "Learning rate:0.0071647667071744\n",
      "Accuracy of the network on the 3268 test sentences:87.48470012239902\n",
      "Time elapsed for epoch:253 is:165.37319254875183\n",
      "[254,   800] loss: 0.000164\n",
      "Learning rate:0.0075980450073344\n",
      "Accuracy of the network on the 3268 test sentences:87.54589963280294\n",
      "Time elapsed for epoch:254 is:165.24640154838562\n",
      "[255,   800] loss: 0.000413\n",
      "Learning rate:0.0080313233074944\n",
      "Accuracy of the network on the 3268 test sentences:87.30110159118728\n",
      "Time elapsed for epoch:255 is:164.84663319587708\n",
      "[256,   800] loss: 0.000311\n",
      "Learning rate:0.0084646016076544\n",
      "Accuracy of the network on the 3268 test sentences:87.02570379436965\n",
      "Time elapsed for epoch:256 is:164.70640683174133\n",
      "[257,   800] loss: 0.000641\n",
      "Learning rate:0.0088978799078144\n",
      "Accuracy of the network on the 3268 test sentences:87.36230110159119\n",
      "Time elapsed for epoch:257 is:164.76601672172546\n",
      "[258,   800] loss: 0.000665\n",
      "Learning rate:0.009331158207974399\n",
      "Accuracy of the network on the 3268 test sentences:87.30110159118728\n",
      "Time elapsed for epoch:258 is:164.57466197013855\n",
      "[259,   800] loss: 0.000346\n",
      "Learning rate:0.0097644365081344\n",
      "Accuracy of the network on the 3268 test sentences:87.11750305997552\n",
      "Time elapsed for epoch:259 is:164.96454906463623\n",
      "[260,   800] loss: 0.000552\n",
      "Learning rate:0.0101977148082944\n",
      "Accuracy of the network on the 3268 test sentences:87.39290085679315\n",
      "Time elapsed for epoch:260 is:165.0561661720276\n",
      "[261,   800] loss: 0.000291\n",
      "Learning rate:0.0106309931084544\n",
      "Accuracy of the network on the 3268 test sentences:87.48470012239902\n",
      "Time elapsed for epoch:261 is:164.63364458084106\n",
      "[262,   800] loss: 0.000437\n",
      "Learning rate:0.0110642714086144\n",
      "Accuracy of the network on the 3268 test sentences:87.51529987760098\n",
      "Time elapsed for epoch:262 is:164.77231335639954\n",
      "[263,   800] loss: 0.000372\n",
      "Learning rate:0.0114975497087744\n",
      "Accuracy of the network on the 3268 test sentences:87.66829865361078\n",
      "Time elapsed for epoch:263 is:164.3726146221161\n",
      "[264,   800] loss: 0.000783\n",
      "Learning rate:0.0119308280089344\n",
      "Accuracy of the network on the 3268 test sentences:86.71970624235006\n",
      "Time elapsed for epoch:264 is:164.5639398097992\n",
      "[265,   800] loss: 0.000952\n",
      "Learning rate:0.012364106309094399\n",
      "Accuracy of the network on the 3268 test sentences:87.08690330477356\n",
      "Time elapsed for epoch:265 is:164.65637016296387\n",
      "[266,   800] loss: 0.000409\n",
      "Learning rate:0.012797384609254399\n",
      "Accuracy of the network on the 3268 test sentences:87.02570379436965\n",
      "Time elapsed for epoch:266 is:164.9265422821045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[267,   800] loss: 0.001044\n",
      "Learning rate:0.013230662909414399\n",
      "Accuracy of the network on the 3268 test sentences:86.44430844553244\n",
      "Time elapsed for epoch:267 is:165.55158925056458\n",
      "[268,   800] loss: 0.000691\n",
      "Learning rate:0.013663941209574398\n",
      "Accuracy of the network on the 3268 test sentences:87.27050183598531\n",
      "Time elapsed for epoch:268 is:164.79097986221313\n",
      "[269,   800] loss: 0.000404\n",
      "Learning rate:0.014097219509734398\n",
      "Accuracy of the network on the 3268 test sentences:87.02570379436965\n",
      "Time elapsed for epoch:269 is:164.67492246627808\n",
      "[270,   800] loss: 0.000938\n",
      "Learning rate:0.014530497809894398\n",
      "Accuracy of the network on the 3268 test sentences:87.08690330477356\n",
      "Time elapsed for epoch:270 is:165.00139546394348\n",
      "[271,   800] loss: 0.001277\n",
      "Learning rate:0.014963776110054398\n",
      "Accuracy of the network on the 3268 test sentences:87.57649938800489\n",
      "Time elapsed for epoch:271 is:164.581303358078\n",
      "[272,   800] loss: 0.000520\n",
      "Learning rate:0.015397054410214397\n",
      "Accuracy of the network on the 3268 test sentences:87.82129742962056\n",
      "Time elapsed for epoch:272 is:164.5053195953369\n",
      "[273,   800] loss: 0.001418\n",
      "Learning rate:0.015830332710374397\n",
      "Accuracy of the network on the 3268 test sentences:86.84210526315789\n",
      "Time elapsed for epoch:273 is:164.75280094146729\n",
      "[274,   800] loss: 0.003228\n",
      "Learning rate:0.0157895701752111\n",
      "Accuracy of the network on the 3268 test sentences:87.11750305997552\n",
      "Time elapsed for epoch:274 is:164.69097900390625\n",
      "[275,   800] loss: 0.001006\n",
      "Learning rate:0.015662438701002868\n",
      "Accuracy of the network on the 3268 test sentences:86.84210526315789\n",
      "Time elapsed for epoch:275 is:165.37738871574402\n",
      "[276,   800] loss: 0.001820\n",
      "Learning rate:0.0154525674193156\n",
      "Accuracy of the network on the 3268 test sentences:86.68910648714811\n",
      "Time elapsed for epoch:276 is:165.20609855651855\n",
      "[277,   800] loss: 0.002255\n",
      "Learning rate:0.015163266125632534\n",
      "Accuracy of the network on the 3268 test sentences:87.30110159118728\n",
      "Time elapsed for epoch:277 is:164.74362969398499\n",
      "[278,   800] loss: 0.001989\n",
      "Learning rate:0.014799097274175266\n",
      "Accuracy of the network on the 3268 test sentences:86.50550795593635\n",
      "Time elapsed for epoch:278 is:164.5695879459381\n",
      "[279,   800] loss: 0.001117\n",
      "Learning rate:0.014365804025275205\n",
      "Accuracy of the network on the 3268 test sentences:87.23990208078335\n",
      "Time elapsed for epoch:279 is:164.38959622383118\n",
      "[280,   800] loss: 0.001556\n",
      "Learning rate:0.013870219672304347\n",
      "Accuracy of the network on the 3268 test sentences:87.57649938800489\n",
      "Time elapsed for epoch:280 is:164.49334192276\n",
      "[281,   800] loss: 0.000912\n",
      "Learning rate:0.013320159876556784\n",
      "Accuracy of the network on the 3268 test sentences:87.14810281517748\n",
      "Time elapsed for epoch:281 is:164.82290983200073\n",
      "[282,   800] loss: 0.000574\n",
      "Learning rate:0.012724299409601247\n",
      "Accuracy of the network on the 3268 test sentences:87.33170134638922\n",
      "Time elapsed for epoch:282 is:165.20560026168823\n",
      "[283,   800] loss: 0.001264\n",
      "Learning rate:0.012092035346951416\n",
      "Accuracy of the network on the 3268 test sentences:87.88249694002448\n",
      "Time elapsed for epoch:283 is:165.31189727783203\n",
      "[284,   800] loss: 0.001321\n",
      "Learning rate:0.011433338870571524\n",
      "Accuracy of the network on the 3268 test sentences:86.56670746634028\n",
      "Time elapsed for epoch:284 is:164.98028182983398\n",
      "[285,   800] loss: 0.000827\n",
      "Learning rate:0.010758598017380282\n",
      "Accuracy of the network on the 3268 test sentences:87.51529987760098\n",
      "Time elapsed for epoch:285 is:165.0498697757721\n",
      "[286,   800] loss: 0.000483\n",
      "Learning rate:0.010078453853703168\n",
      "Accuracy of the network on the 3268 test sentences:87.27050183598531\n",
      "Time elapsed for epoch:286 is:164.6087520122528\n",
      "[287,   800] loss: 0.001013\n",
      "Learning rate:0.009403632659299792\n",
      "Accuracy of the network on the 3268 test sentences:87.51529987760098\n",
      "Time elapsed for epoch:287 is:164.71985816955566\n",
      "[288,   800] loss: 0.000926\n",
      "Learning rate:0.008744776767524541\n",
      "Accuracy of the network on the 3268 test sentences:87.94369645042839\n",
      "Saved checkpoint to:./imdb_net_learnable_pooling_sgd_lr_0.00599875_gamma_0.88_500_epochs_32_batch.pth\n",
      "Time elapsed for epoch:288 is:164.92026662826538\n",
      "[289,   800] loss: 0.000456\n",
      "Learning rate:0.008112276729372144\n",
      "Accuracy of the network on the 3268 test sentences:87.23990208078335\n",
      "Time elapsed for epoch:289 is:164.88866114616394\n",
      "[290,   800] loss: 0.000582\n",
      "Learning rate:0.007516107448281472\n",
      "Accuracy of the network on the 3268 test sentences:87.17870257037944\n",
      "Time elapsed for epoch:290 is:165.3517575263977\n",
      "[291,   800] loss: 0.000297\n",
      "Learning rate:0.006965670869949588\n",
      "Accuracy of the network on the 3268 test sentences:86.93390452876378\n",
      "Time elapsed for epoch:291 is:165.5072693824768\n",
      "[292,   800] loss: 0.000292\n",
      "Learning rate:0.006469647708031666\n",
      "Accuracy of the network on the 3268 test sentences:87.51529987760098\n",
      "Time elapsed for epoch:292 is:164.98223209381104\n",
      "[293,   800] loss: 0.000715\n",
      "Learning rate:0.006035860544101018\n",
      "Accuracy of the network on the 3268 test sentences:87.33170134638922\n",
      "Time elapsed for epoch:293 is:164.92907905578613\n",
      "[294,   800] loss: 0.000103\n",
      "Learning rate:0.005671150460864726\n",
      "Accuracy of the network on the 3268 test sentences:87.17870257037944\n",
      "Time elapsed for epoch:294 is:165.18234014511108\n",
      "[295,   800] loss: 0.000400\n",
      "Learning rate:0.005381269154202668\n",
      "Accuracy of the network on the 3268 test sentences:87.17870257037944\n",
      "Time elapsed for epoch:295 is:164.71520590782166\n",
      "[296,   800] loss: 0.000241\n",
      "Learning rate:0.005170788225487606\n",
      "Accuracy of the network on the 3268 test sentences:87.08690330477356\n",
      "Time elapsed for epoch:296 is:164.73623514175415\n",
      "[297,   800] loss: 0.000231\n",
      "Learning rate:0.005043027084700586\n",
      "Accuracy of the network on the 3268 test sentences:87.39290085679315\n",
      "Time elapsed for epoch:297 is:165.0003514289856\n",
      "[298,   800] loss: 0.000192\n",
      "Learning rate:0.005000000601352626\n",
      "Accuracy of the network on the 3268 test sentences:86.75030599755202\n",
      "Time elapsed for epoch:298 is:165.45875716209412\n",
      "[299,   800] loss: 0.000142\n",
      "Learning rate:0.005355945085750272\n",
      "Accuracy of the network on the 3268 test sentences:87.17870257037944\n",
      "Time elapsed for epoch:299 is:165.19687461853027\n",
      "[300,   800] loss: 0.000361\n",
      "Learning rate:0.005713229989891072\n",
      "Accuracy of the network on the 3268 test sentences:87.23990208078335\n",
      "Time elapsed for epoch:300 is:164.84008622169495\n",
      "[301,   800] loss: 0.000570\n",
      "Learning rate:0.006070514894031872\n",
      "Accuracy of the network on the 3268 test sentences:86.93390452876378\n",
      "Time elapsed for epoch:301 is:165.0977246761322\n",
      "[302,   800] loss: 0.000334\n",
      "Learning rate:0.006427799798172672\n",
      "Accuracy of the network on the 3268 test sentences:87.51529987760098\n",
      "Time elapsed for epoch:302 is:164.7591335773468\n",
      "[303,   800] loss: 0.000448\n",
      "Learning rate:0.0067850847023134715\n",
      "Accuracy of the network on the 3268 test sentences:87.02570379436965\n",
      "Time elapsed for epoch:303 is:164.54816198349\n",
      "[304,   800] loss: 0.000403\n",
      "Learning rate:0.007142369606454271\n",
      "Accuracy of the network on the 3268 test sentences:87.36230110159119\n",
      "Time elapsed for epoch:304 is:164.81497406959534\n",
      "[305,   800] loss: 0.000461\n",
      "Learning rate:0.007499654510595071\n",
      "Accuracy of the network on the 3268 test sentences:87.20930232558139\n",
      "Time elapsed for epoch:305 is:165.2196910381317\n",
      "[306,   800] loss: 0.000086\n",
      "Learning rate:0.007856939414735871\n",
      "Accuracy of the network on the 3268 test sentences:87.63769889840881\n",
      "Time elapsed for epoch:306 is:165.51332831382751\n",
      "[307,   800] loss: 0.000360\n",
      "Learning rate:0.00821422431887667\n",
      "Accuracy of the network on the 3268 test sentences:87.27050183598531\n",
      "Time elapsed for epoch:307 is:164.9623031616211\n",
      "[308,   800] loss: 0.000299\n",
      "Learning rate:0.00857150922301747\n",
      "Accuracy of the network on the 3268 test sentences:87.08690330477356\n",
      "Time elapsed for epoch:308 is:164.78614497184753\n",
      "[309,   800] loss: 0.001204\n",
      "Learning rate:0.00892879412715827\n",
      "Accuracy of the network on the 3268 test sentences:87.39290085679315\n",
      "Time elapsed for epoch:309 is:164.7700159549713\n",
      "[310,   800] loss: 0.000394\n",
      "Learning rate:0.009286079031299072\n",
      "Accuracy of the network on the 3268 test sentences:87.27050183598531\n",
      "Time elapsed for epoch:310 is:164.75223016738892\n",
      "[311,   800] loss: 0.000272\n",
      "Learning rate:0.009643363935439872\n",
      "Accuracy of the network on the 3268 test sentences:88.06609547123622\n",
      "Saved checkpoint to:./imdb_net_learnable_pooling_sgd_lr_0.00599875_gamma_0.88_500_epochs_32_batch.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed for epoch:311 is:164.84223985671997\n",
      "[312,   800] loss: 0.001222\n",
      "Learning rate:0.010000648839580671\n",
      "Accuracy of the network on the 3268 test sentences:87.11750305997552\n",
      "Time elapsed for epoch:312 is:165.18162608146667\n",
      "[313,   800] loss: 0.000460\n",
      "Learning rate:0.010357933743721471\n",
      "Accuracy of the network on the 3268 test sentences:87.91309669522644\n",
      "Time elapsed for epoch:313 is:165.4921748638153\n",
      "[314,   800] loss: 0.000190\n",
      "Learning rate:0.010715218647862271\n",
      "Accuracy of the network on the 3268 test sentences:86.96450428396572\n",
      "Time elapsed for epoch:314 is:165.4218590259552\n",
      "[315,   800] loss: 0.000053\n",
      "Learning rate:0.011072503552003071\n",
      "Accuracy of the network on the 3268 test sentences:87.20930232558139\n",
      "Time elapsed for epoch:315 is:165.25895810127258\n",
      "[316,   800] loss: 0.000192\n",
      "Learning rate:0.01142978845614387\n",
      "Accuracy of the network on the 3268 test sentences:87.36230110159119\n",
      "Time elapsed for epoch:316 is:165.21786761283875\n",
      "[317,   800] loss: 0.000185\n",
      "Learning rate:0.011787073360284672\n",
      "Accuracy of the network on the 3268 test sentences:87.51529987760098\n",
      "Time elapsed for epoch:317 is:165.09335613250732\n",
      "[318,   800] loss: 0.000625\n",
      "Learning rate:0.01214435826442547\n",
      "Accuracy of the network on the 3268 test sentences:87.82129742962056\n",
      "Time elapsed for epoch:318 is:164.65398836135864\n",
      "[319,   800] loss: 0.001213\n",
      "Learning rate:0.012501643168566272\n",
      "Accuracy of the network on the 3268 test sentences:87.20930232558139\n",
      "Time elapsed for epoch:319 is:164.63250064849854\n",
      "[320,   800] loss: 0.000194\n",
      "Learning rate:0.012858928072707072\n",
      "Accuracy of the network on the 3268 test sentences:87.02570379436965\n",
      "Time elapsed for epoch:320 is:165.16144227981567\n",
      "[321,   800] loss: 0.000970\n",
      "Learning rate:0.013216212976847871\n",
      "Accuracy of the network on the 3268 test sentences:87.76009791921665\n",
      "Time elapsed for epoch:321 is:165.44821286201477\n",
      "[322,   800] loss: 0.000571\n",
      "Learning rate:0.013573497880988671\n",
      "Accuracy of the network on the 3268 test sentences:87.42350061199511\n",
      "Time elapsed for epoch:322 is:165.18265104293823\n",
      "[323,   800] loss: 0.001200\n",
      "Learning rate:0.013930782785129471\n",
      "Accuracy of the network on the 3268 test sentences:87.14810281517748\n",
      "Time elapsed for epoch:323 is:164.8421971797943\n",
      "[324,   800] loss: 0.001370\n",
      "Learning rate:0.013897169658270873\n",
      "Accuracy of the network on the 3268 test sentences:87.45410036719706\n",
      "Time elapsed for epoch:324 is:165.19626927375793\n",
      "[325,   800] loss: 0.001374\n",
      "Learning rate:0.013792335983104143\n",
      "Accuracy of the network on the 3268 test sentences:87.33170134638922\n",
      "Time elapsed for epoch:325 is:164.70705008506775\n",
      "[326,   800] loss: 0.000831\n",
      "Learning rate:0.013619274371821387\n",
      "Accuracy of the network on the 3268 test sentences:86.99510403916769\n",
      "Time elapsed for epoch:326 is:164.75724697113037\n",
      "[327,   800] loss: 0.000921\n",
      "Learning rate:0.013380714109414538\n",
      "Accuracy of the network on the 3268 test sentences:87.05630354957161\n",
      "Time elapsed for epoch:327 is:164.90542721748352\n",
      "[328,   800] loss: 0.001206\n",
      "Learning rate:0.01308041743373074\n",
      "Accuracy of the network on the 3268 test sentences:87.20930232558139\n",
      "Time elapsed for epoch:328 is:165.27280592918396\n",
      "[329,   800] loss: 0.000245\n",
      "Learning rate:0.012723120202734065\n",
      "Accuracy of the network on the 3268 test sentences:87.23990208078335\n",
      "Time elapsed for epoch:329 is:165.17054176330566\n",
      "[330,   800] loss: 0.000459\n",
      "Learning rate:0.012314457207196353\n",
      "Accuracy of the network on the 3268 test sentences:86.99510403916769\n",
      "Time elapsed for epoch:330 is:164.79046630859375\n",
      "[331,   800] loss: 0.000675\n",
      "Learning rate:0.011860873306680675\n",
      "Accuracy of the network on the 3268 test sentences:87.30110159118728\n",
      "Time elapsed for epoch:331 is:164.91727089881897\n",
      "[332,   800] loss: 0.000794\n",
      "Learning rate:0.011369521790256045\n",
      "Accuracy of the network on the 3268 test sentences:87.39290085679315\n",
      "Time elapsed for epoch:332 is:164.72488498687744\n",
      "[333,   800] loss: 0.000782\n",
      "Learning rate:0.010848151564855656\n",
      "Accuracy of the network on the 3268 test sentences:87.27050183598531\n",
      "Time elapsed for epoch:333 is:164.63294959068298\n",
      "[334,   800] loss: 0.000779\n",
      "Learning rate:0.010304984950385543\n",
      "Accuracy of the network on the 3268 test sentences:87.27050183598531\n",
      "Time elapsed for epoch:334 is:164.71180510520935\n",
      "[335,   800] loss: 0.000141\n",
      "Learning rate:0.00974858800882791\n",
      "Accuracy of the network on the 3268 test sentences:86.84210526315789\n",
      "Time elapsed for epoch:335 is:165.43927669525146\n",
      "[336,   800] loss: 0.000453\n",
      "Learning rate:0.009187735452326541\n",
      "Accuracy of the network on the 3268 test sentences:86.81150550795594\n",
      "Time elapsed for epoch:336 is:165.7006175518036\n",
      "[337,   800] loss: 0.000147\n",
      "Learning rate:0.008631272260734542\n",
      "Accuracy of the network on the 3268 test sentences:87.42350061199511\n",
      "Time elapsed for epoch:337 is:165.395339012146\n",
      "[338,   800] loss: 0.000871\n",
      "Learning rate:0.008087974190998314\n",
      "Accuracy of the network on the 3268 test sentences:88.28029375764994\n",
      "Saved checkpoint to:./imdb_net_learnable_pooling_sgd_lr_0.00599875_gamma_0.88_500_epochs_32_batch.pth\n",
      "Time elapsed for epoch:338 is:165.61349940299988\n",
      "[339,   800] loss: 0.000214\n",
      "Learning rate:0.007566409378228135\n",
      "Accuracy of the network on the 3268 test sentences:87.94369645042839\n",
      "Time elapsed for epoch:339 is:165.04195427894592\n",
      "[340,   800] loss: 0.000269\n",
      "Learning rate:0.007074803211089109\n",
      "Accuracy of the network on the 3268 test sentences:87.63769889840881\n",
      "Time elapsed for epoch:340 is:164.92027068138123\n",
      "[341,   800] loss: 0.000741\n",
      "Learning rate:0.006620908612508303\n",
      "Accuracy of the network on the 3268 test sentences:87.60709914320685\n",
      "Time elapsed for epoch:341 is:164.81869077682495\n",
      "[342,   800] loss: 0.000217\n",
      "Learning rate:0.006211883771448832\n",
      "Accuracy of the network on the 3268 test sentences:87.97429620563035\n",
      "Time elapsed for epoch:342 is:164.84329891204834\n",
      "[343,   800] loss: 0.000057\n",
      "Learning rate:0.0058541792539937975\n",
      "Accuracy of the network on the 3268 test sentences:87.54589963280294\n",
      "Time elapsed for epoch:343 is:165.08671021461487\n",
      "[344,   800] loss: 0.000725\n",
      "Learning rate:0.005553436274065786\n",
      "Accuracy of the network on the 3268 test sentences:87.05630354957161\n",
      "Time elapsed for epoch:344 is:165.23549461364746\n",
      "[345,   800] loss: 0.000233\n",
      "Learning rate:0.00531439772811341\n",
      "Accuracy of the network on the 3268 test sentences:87.20930232558139\n",
      "Time elapsed for epoch:345 is:165.23238730430603\n",
      "[346,   800] loss: 0.000128\n",
      "Learning rate:0.005140833396801048\n",
      "Accuracy of the network on the 3268 test sentences:87.57649938800489\n",
      "Time elapsed for epoch:346 is:165.03711318969727\n",
      "[347,   800] loss: 0.000404\n",
      "Learning rate:0.005035480493315797\n",
      "Accuracy of the network on the 3268 test sentences:87.63769889840881\n",
      "Time elapsed for epoch:347 is:164.66764616966248\n",
      "[348,   800] loss: 0.000069\n",
      "Learning rate:0.005000000495880397\n",
      "Accuracy of the network on the 3268 test sentences:87.66829865361078\n",
      "Time elapsed for epoch:348 is:164.84332394599915\n",
      "[349,   800] loss: 0.000051\n",
      "Learning rate:0.005289321675460239\n",
      "Accuracy of the network on the 3268 test sentences:87.33170134638922\n",
      "Time elapsed for epoch:349 is:164.74367570877075\n",
      "[350,   800] loss: 0.000143\n",
      "Learning rate:0.0055797323911041434\n",
      "Accuracy of the network on the 3268 test sentences:87.91309669522644\n",
      "Time elapsed for epoch:350 is:164.87802982330322\n",
      "[351,   800] loss: 0.000074\n",
      "Learning rate:0.0058701431067480474\n",
      "Accuracy of the network on the 3268 test sentences:87.76009791921665\n",
      "Time elapsed for epoch:351 is:165.37585949897766\n",
      "[352,   800] loss: 0.000069\n",
      "Learning rate:0.0061605538223919514\n",
      "Accuracy of the network on the 3268 test sentences:88.06609547123622\n",
      "Time elapsed for epoch:352 is:165.3901605606079\n",
      "[353,   800] loss: 0.000189\n",
      "Learning rate:0.0064509645380358555\n",
      "Accuracy of the network on the 3268 test sentences:87.63769889840881\n",
      "Time elapsed for epoch:353 is:164.9100902080536\n",
      "[354,   800] loss: 0.000048\n",
      "Learning rate:0.0067413752536797595\n",
      "Accuracy of the network on the 3268 test sentences:88.15789473684211\n",
      "Time elapsed for epoch:354 is:164.76910209655762\n",
      "[355,   800] loss: 0.000026\n",
      "Learning rate:0.0070317859693236635\n",
      "Accuracy of the network on the 3268 test sentences:87.57649938800489\n",
      "Time elapsed for epoch:355 is:164.68832635879517\n",
      "[356,   800] loss: 0.000179\n",
      "Learning rate:0.0073221966849675675\n",
      "Accuracy of the network on the 3268 test sentences:87.82129742962056\n",
      "Time elapsed for epoch:356 is:164.8240327835083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[357,   800] loss: 0.000323\n",
      "Learning rate:0.0076126074006114715\n",
      "Accuracy of the network on the 3268 test sentences:88.49449204406365\n",
      "Saved checkpoint to:./imdb_net_learnable_pooling_sgd_lr_0.00599875_gamma_0.88_500_epochs_32_batch.pth\n",
      "Time elapsed for epoch:357 is:165.21386861801147\n",
      "[358,   800] loss: 0.000061\n",
      "Learning rate:0.007903018116255375\n",
      "Accuracy of the network on the 3268 test sentences:88.06609547123622\n",
      "Time elapsed for epoch:358 is:165.10788297653198\n",
      "[359,   800] loss: 0.000130\n",
      "Learning rate:0.00819342883189928\n",
      "Accuracy of the network on the 3268 test sentences:87.60709914320685\n",
      "Time elapsed for epoch:359 is:165.53601026535034\n",
      "[360,   800] loss: 0.000061\n",
      "Learning rate:0.008483839547543183\n",
      "Accuracy of the network on the 3268 test sentences:87.23990208078335\n",
      "Time elapsed for epoch:360 is:165.43116545677185\n",
      "[361,   800] loss: 0.000028\n",
      "Learning rate:0.008774250263187088\n",
      "Accuracy of the network on the 3268 test sentences:87.60709914320685\n",
      "Time elapsed for epoch:361 is:165.12165665626526\n",
      "[362,   800] loss: 0.000246\n",
      "Learning rate:0.00906466097883099\n",
      "Accuracy of the network on the 3268 test sentences:88.12729498164015\n",
      "Time elapsed for epoch:362 is:164.63013792037964\n",
      "[363,   800] loss: 0.000200\n",
      "Learning rate:0.009355071694474896\n",
      "Accuracy of the network on the 3268 test sentences:87.48470012239902\n",
      "Time elapsed for epoch:363 is:164.77405261993408\n",
      "[364,   800] loss: 0.000235\n",
      "Learning rate:0.0096454824101188\n",
      "Accuracy of the network on the 3268 test sentences:87.76009791921665\n",
      "Time elapsed for epoch:364 is:164.6268229484558\n",
      "[365,   800] loss: 0.000904\n",
      "Learning rate:0.009935893125762704\n",
      "Accuracy of the network on the 3268 test sentences:87.05630354957161\n",
      "Time elapsed for epoch:365 is:164.93478631973267\n",
      "[366,   800] loss: 0.000209\n",
      "Learning rate:0.010226303841406607\n",
      "Accuracy of the network on the 3268 test sentences:86.99510403916769\n",
      "Time elapsed for epoch:366 is:165.02365970611572\n",
      "[367,   800] loss: 0.000161\n",
      "Learning rate:0.010516714557050512\n",
      "Accuracy of the network on the 3268 test sentences:87.48470012239902\n",
      "Time elapsed for epoch:367 is:165.2504026889801\n",
      "[368,   800] loss: 0.000577\n",
      "Learning rate:0.010807125272694416\n",
      "Accuracy of the network on the 3268 test sentences:87.88249694002448\n",
      "Time elapsed for epoch:368 is:164.93723821640015\n",
      "[369,   800] loss: 0.000060\n",
      "Learning rate:0.01109753598833832\n",
      "Accuracy of the network on the 3268 test sentences:87.85189718482252\n",
      "Time elapsed for epoch:369 is:164.8278510570526\n",
      "[370,   800] loss: 0.000471\n",
      "Learning rate:0.011387946703982223\n",
      "Accuracy of the network on the 3268 test sentences:87.82129742962056\n",
      "Time elapsed for epoch:370 is:164.5943374633789\n",
      "[371,   800] loss: 0.000732\n",
      "Learning rate:0.011678357419626126\n",
      "Accuracy of the network on the 3268 test sentences:87.60709914320685\n",
      "Time elapsed for epoch:371 is:164.56204056739807\n",
      "[372,   800] loss: 0.000110\n",
      "Learning rate:0.01196876813527003\n",
      "Accuracy of the network on the 3268 test sentences:88.15789473684211\n",
      "Time elapsed for epoch:372 is:164.62959265708923\n",
      "[373,   800] loss: 0.000842\n",
      "Learning rate:0.012259178850913936\n",
      "Accuracy of the network on the 3268 test sentences:87.76009791921665\n",
      "Time elapsed for epoch:373 is:165.122141122818\n",
      "[374,   800] loss: 0.000760\n",
      "Learning rate:0.012231857203363478\n",
      "Accuracy of the network on the 3268 test sentences:86.90330477356181\n",
      "Time elapsed for epoch:374 is:165.36830472946167\n",
      "[375,   800] loss: 0.000652\n",
      "Learning rate:0.012146645591353266\n",
      "Accuracy of the network on the 3268 test sentences:87.60709914320685\n",
      "Time elapsed for epoch:375 is:165.22372364997864\n",
      "[376,   800] loss: 0.000217\n",
      "Learning rate:0.012005976490026484\n",
      "Accuracy of the network on the 3268 test sentences:87.14810281517748\n",
      "Time elapsed for epoch:376 is:164.94294714927673\n",
      "[377,   800] loss: 0.001222\n",
      "Learning rate:0.011812068335142704\n",
      "Accuracy of the network on the 3268 test sentences:87.51529987760098\n",
      "Time elapsed for epoch:377 is:164.94013261795044\n",
      "[378,   800] loss: 0.000515\n",
      "Learning rate:0.011567979174139558\n",
      "Accuracy of the network on the 3268 test sentences:87.30110159118728\n",
      "Time elapsed for epoch:378 is:164.87025785446167\n",
      "[379,   800] loss: 0.000828\n",
      "Learning rate:0.011277558438897863\n",
      "Accuracy of the network on the 3268 test sentences:88.34149326805385\n",
      "Time elapsed for epoch:379 is:164.87690711021423\n",
      "[380,   800] loss: 0.000181\n",
      "Learning rate:0.010945386237901322\n",
      "Accuracy of the network on the 3268 test sentences:87.69889840881272\n",
      "Time elapsed for epoch:380 is:164.9581036567688\n",
      "[381,   800] loss: 0.000509\n",
      "Learning rate:0.0105767011251897\n",
      "Accuracy of the network on the 3268 test sentences:87.66829865361078\n",
      "Time elapsed for epoch:381 is:165.03003025054932\n",
      "[382,   800] loss: 0.000452\n",
      "Learning rate:0.01017731748523227\n",
      "Accuracy of the network on the 3268 test sentences:88.18849449204406\n",
      "Time elapsed for epoch:382 is:165.2720673084259\n",
      "[383,   800] loss: 0.000141\n",
      "Learning rate:0.009753533836611386\n",
      "Accuracy of the network on the 3268 test sentences:87.72949816401469\n",
      "Time elapsed for epoch:383 is:165.03617572784424\n",
      "[384,   800] loss: 0.000159\n",
      "Learning rate:0.009312033500621878\n",
      "Accuracy of the network on the 3268 test sentences:87.54589963280294\n",
      "Time elapsed for epoch:384 is:166.62518548965454\n",
      "[385,   800] loss: 0.000117\n",
      "Learning rate:0.00885977920130182\n",
      "Accuracy of the network on the 3268 test sentences:87.63769889840881\n",
      "Time elapsed for epoch:385 is:164.9543058872223\n",
      "[386,   800] loss: 0.000166\n",
      "Learning rate:0.00840390325911511\n",
      "Accuracy of the network on the 3268 test sentences:87.76009791921665\n",
      "Time elapsed for epoch:386 is:164.65942478179932\n",
      "[387,   800] loss: 0.000552\n",
      "Learning rate:0.007951595109997121\n",
      "Accuracy of the network on the 3268 test sentences:87.88249694002448\n",
      "Time elapsed for epoch:387 is:164.50255942344666\n",
      "[388,   800] loss: 0.000277\n",
      "Learning rate:0.007509987923655235\n",
      "Accuracy of the network on the 3268 test sentences:87.33170134638922\n",
      "Time elapsed for epoch:388 is:164.87771224975586\n",
      "[389,   800] loss: 0.000032\n",
      "Learning rate:0.007086046109221408\n",
      "Accuracy of the network on the 3268 test sentences:87.82129742962056\n",
      "Time elapsed for epoch:389 is:165.06031131744385\n",
      "[390,   800] loss: 0.000230\n",
      "Learning rate:0.006686455482359829\n",
      "Accuracy of the network on the 3268 test sentences:87.97429620563035\n",
      "Time elapsed for epoch:390 is:165.53655219078064\n",
      "[391,   800] loss: 0.000238\n",
      "Learning rate:0.006317517825959972\n",
      "Accuracy of the network on the 3268 test sentences:88.34149326805385\n",
      "Time elapsed for epoch:391 is:165.11035656929016\n",
      "[392,   800] loss: 0.000148\n",
      "Learning rate:0.005985051507255939\n",
      "Accuracy of the network on the 3268 test sentences:87.88249694002448\n",
      "Time elapsed for epoch:392 is:165.0903878211975\n",
      "[393,   800] loss: 0.000222\n",
      "Learning rate:0.005694299718699443\n",
      "Accuracy of the network on the 3268 test sentences:87.33170134638922\n",
      "Time elapsed for epoch:393 is:164.99713683128357\n",
      "[394,   800] loss: 0.000042\n",
      "Learning rate:0.0054498477896827175\n",
      "Accuracy of the network on the 3268 test sentences:87.97429620563035\n",
      "Time elapsed for epoch:394 is:164.62626838684082\n",
      "[395,   800] loss: 0.000091\n",
      "Learning rate:0.005255550873154863\n",
      "Accuracy of the network on the 3268 test sentences:88.24969400244798\n",
      "Time elapsed for epoch:395 is:165.0107011795044\n",
      "[396,   800] loss: 0.000068\n",
      "Learning rate:0.005114473147556876\n",
      "Accuracy of the network on the 3268 test sentences:87.76009791921665\n",
      "Time elapsed for epoch:396 is:164.9262113571167\n",
      "[397,   800] loss: 0.000084\n",
      "Learning rate:0.005028839492897183\n",
      "Accuracy of the network on the 3268 test sentences:88.09669522643819\n",
      "Time elapsed for epoch:397 is:164.495103597641\n",
      "[398,   800] loss: 0.000204\n",
      "Learning rate:0.005000000403064834\n",
      "Accuracy of the network on the 3268 test sentences:87.69889840881272\n",
      "Time elapsed for epoch:398 is:164.9781928062439\n",
      "[399,   800] loss: 0.000036\n",
      "Learning rate:0.005230693074405011\n",
      "Accuracy of the network on the 3268 test sentences:87.91309669522644\n",
      "Time elapsed for epoch:399 is:165.0743691921234\n",
      "[400,   800] loss: 0.000024\n",
      "Learning rate:0.005462254504171646\n",
      "Accuracy of the network on the 3268 test sentences:88.03549571603428\n",
      "Time elapsed for epoch:400 is:165.1756911277771\n",
      "[401,   800] loss: 0.000180\n",
      "Learning rate:0.005693815933938281\n",
      "Accuracy of the network on the 3268 test sentences:87.36230110159119\n",
      "Time elapsed for epoch:401 is:164.91288208961487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[402,   800] loss: 0.000631\n",
      "Learning rate:0.005925377363704918\n",
      "Accuracy of the network on the 3268 test sentences:87.97429620563035\n",
      "Time elapsed for epoch:402 is:164.93875527381897\n",
      "[403,   800] loss: 0.000078\n",
      "Learning rate:0.006156938793471553\n",
      "Accuracy of the network on the 3268 test sentences:86.96450428396572\n",
      "Time elapsed for epoch:403 is:164.56882333755493\n",
      "[404,   800] loss: 0.000459\n",
      "Learning rate:0.006388500223238188\n",
      "Accuracy of the network on the 3268 test sentences:87.94369645042839\n",
      "Time elapsed for epoch:404 is:164.9343957901001\n",
      "[405,   800] loss: 0.000178\n",
      "Learning rate:0.006620061653004824\n",
      "Accuracy of the network on the 3268 test sentences:87.69889840881272\n",
      "Time elapsed for epoch:405 is:164.54396080970764\n",
      "[406,   800] loss: 0.000144\n",
      "Learning rate:0.006851623082771459\n",
      "Accuracy of the network on the 3268 test sentences:87.82129742962056\n",
      "Time elapsed for epoch:406 is:164.84993934631348\n",
      "[407,   800] loss: 0.000044\n",
      "Learning rate:0.007083184512538095\n",
      "Accuracy of the network on the 3268 test sentences:88.00489596083231\n",
      "Time elapsed for epoch:407 is:166.38982796669006\n",
      "[408,   800] loss: 0.000256\n",
      "Learning rate:0.00731474594230473\n",
      "Accuracy of the network on the 3268 test sentences:87.66829865361078\n",
      "Time elapsed for epoch:408 is:165.11106896400452\n",
      "[409,   800] loss: 0.000017\n",
      "Learning rate:0.007546307372071365\n",
      "Accuracy of the network on the 3268 test sentences:87.72949816401469\n",
      "Time elapsed for epoch:409 is:165.25025296211243\n",
      "[410,   800] loss: 0.000189\n",
      "Learning rate:0.007777868801838001\n",
      "Accuracy of the network on the 3268 test sentences:88.49449204406365\n",
      "Time elapsed for epoch:410 is:164.70048666000366\n",
      "[411,   800] loss: 0.000093\n",
      "Learning rate:0.008009430231604636\n",
      "Accuracy of the network on the 3268 test sentences:87.60709914320685\n",
      "Time elapsed for epoch:411 is:164.92099237442017\n",
      "[412,   800] loss: 0.000187\n",
      "Learning rate:0.008240991661371273\n",
      "Accuracy of the network on the 3268 test sentences:87.72949816401469\n",
      "Time elapsed for epoch:412 is:164.55885410308838\n",
      "[413,   800] loss: 0.000025\n",
      "Learning rate:0.008472553091137907\n",
      "Accuracy of the network on the 3268 test sentences:88.09669522643819\n",
      "Time elapsed for epoch:413 is:164.58422708511353\n",
      "[414,   800] loss: 0.000770\n",
      "Learning rate:0.008704114520904544\n",
      "Accuracy of the network on the 3268 test sentences:87.69889840881272\n",
      "Time elapsed for epoch:414 is:164.66445636749268\n",
      "[415,   800] loss: 0.000277\n",
      "Learning rate:0.008935675950671178\n",
      "Accuracy of the network on the 3268 test sentences:88.12729498164015\n",
      "Time elapsed for epoch:415 is:164.55052518844604\n",
      "[416,   800] loss: 0.000246\n",
      "Learning rate:0.009167237380437815\n",
      "Accuracy of the network on the 3268 test sentences:87.51529987760098\n",
      "Time elapsed for epoch:416 is:164.65407943725586\n",
      "[417,   800] loss: 0.000125\n",
      "Learning rate:0.009398798810204449\n",
      "Accuracy of the network on the 3268 test sentences:87.57649938800489\n",
      "Time elapsed for epoch:417 is:164.6175663471222\n",
      "[418,   800] loss: 0.000043\n",
      "Learning rate:0.009630360239971086\n",
      "Accuracy of the network on the 3268 test sentences:87.60709914320685\n",
      "Time elapsed for epoch:418 is:165.0104649066925\n",
      "[419,   800] loss: 0.000012\n",
      "Learning rate:0.00986192166973772\n",
      "Accuracy of the network on the 3268 test sentences:88.09669522643819\n",
      "Time elapsed for epoch:419 is:165.28909134864807\n",
      "[420,   800] loss: 0.000104\n",
      "Learning rate:0.010093483099504356\n",
      "Accuracy of the network on the 3268 test sentences:88.09669522643819\n",
      "Time elapsed for epoch:420 is:165.1829969882965\n",
      "[421,   800] loss: 0.000163\n",
      "Learning rate:0.01032504452927099\n",
      "Accuracy of the network on the 3268 test sentences:87.60709914320685\n",
      "Time elapsed for epoch:421 is:165.08525371551514\n",
      "[422,   800] loss: 0.000040\n",
      "Learning rate:0.010556605959037627\n",
      "Accuracy of the network on the 3268 test sentences:88.00489596083231\n",
      "Time elapsed for epoch:422 is:164.88090920448303\n",
      "[423,   800] loss: 0.000256\n",
      "Learning rate:0.010788167388804263\n",
      "Accuracy of the network on the 3268 test sentences:87.72949816401469\n",
      "Time elapsed for epoch:423 is:164.79982542991638\n",
      "[424,   800] loss: 0.000168\n",
      "Learning rate:0.010766382243044964\n",
      "Accuracy of the network on the 3268 test sentences:87.72949816401469\n",
      "Time elapsed for epoch:424 is:165.23575234413147\n",
      "[425,   800] loss: 0.000751\n",
      "Learning rate:0.010698438046612493\n",
      "Accuracy of the network on the 3268 test sentences:87.42350061199511\n",
      "Time elapsed for epoch:425 is:164.4873390197754\n",
      "[426,   800] loss: 0.000257\n",
      "Learning rate:0.010586274354046967\n",
      "Accuracy of the network on the 3268 test sentences:87.72949816401469\n",
      "Time elapsed for epoch:426 is:164.74729752540588\n",
      "[427,   800] loss: 0.000376\n",
      "Learning rate:0.010431660053783489\n",
      "Accuracy of the network on the 3268 test sentences:87.66829865361078\n",
      "Time elapsed for epoch:427 is:166.02871799468994\n",
      "[428,   800] loss: 0.000138\n",
      "Learning rate:0.010237033505699315\n",
      "Accuracy of the network on the 3268 test sentences:87.45410036719706\n",
      "Time elapsed for epoch:428 is:165.8364360332489\n",
      "[429,   800] loss: 0.000308\n",
      "Learning rate:0.010005464086722003\n",
      "Accuracy of the network on the 3268 test sentences:87.91309669522644\n",
      "Time elapsed for epoch:429 is:165.34285378456116\n",
      "[430,   800] loss: 0.000134\n",
      "Learning rate:0.00974060378492169\n",
      "Accuracy of the network on the 3268 test sentences:87.82129742962056\n",
      "Time elapsed for epoch:430 is:165.07277846336365\n",
      "[431,   800] loss: 0.000111\n",
      "Learning rate:0.009446629605477638\n",
      "Accuracy of the network on the 3268 test sentences:87.54589963280294\n",
      "Time elapsed for epoch:431 is:165.05461764335632\n",
      "[432,   800] loss: 0.000135\n",
      "Learning rate:0.009128177696811346\n",
      "Accuracy of the network on the 3268 test sentences:87.85189718482252\n",
      "Time elapsed for epoch:432 is:164.69383597373962\n",
      "[433,   800] loss: 0.000446\n",
      "Learning rate:0.008790270235756428\n",
      "Accuracy of the network on the 3268 test sentences:88.37209302325581\n",
      "Time elapsed for epoch:433 is:164.70013761520386\n",
      "[434,   800] loss: 0.000055\n",
      "Learning rate:0.008438236224829854\n",
      "Accuracy of the network on the 3268 test sentences:87.72949816401469\n",
      "Time elapsed for epoch:434 is:164.6159930229187\n",
      "[435,   800] loss: 0.000068\n",
      "Learning rate:0.008077627450678861\n",
      "Accuracy of the network on the 3268 test sentences:88.40269277845778\n",
      "Time elapsed for epoch:435 is:164.51023745536804\n",
      "[436,   800] loss: 0.000231\n",
      "Learning rate:0.007714130929089052\n",
      "Accuracy of the network on the 3268 test sentences:87.42350061199511\n",
      "Time elapsed for epoch:436 is:164.5848925113678\n",
      "[437,   800] loss: 0.000562\n",
      "Learning rate:0.007353479217348191\n",
      "Accuracy of the network on the 3268 test sentences:87.05630354957161\n",
      "Time elapsed for epoch:437 is:164.65174555778503\n",
      "[438,   800] loss: 0.000105\n",
      "Learning rate:0.007001360008393324\n",
      "Accuracy of the network on the 3268 test sentences:87.85189718482252\n",
      "Time elapsed for epoch:438 is:164.80895566940308\n",
      "[439,   800] loss: 0.000017\n",
      "Learning rate:0.006663326432495488\n",
      "Accuracy of the network on the 3268 test sentences:87.60709914320685\n",
      "Time elapsed for epoch:439 is:165.15673780441284\n",
      "[440,   800] loss: 0.000463\n",
      "Learning rate:0.006344709481078063\n",
      "Accuracy of the network on the 3268 test sentences:87.76009791921665\n",
      "Time elapsed for epoch:440 is:165.0092613697052\n",
      "[441,   800] loss: 0.000340\n",
      "Learning rate:0.006050533933797441\n",
      "Accuracy of the network on the 3268 test sentences:87.54589963280294\n",
      "Time elapsed for epoch:441 is:164.83658719062805\n",
      "[442,   800] loss: 0.000194\n",
      "Learning rate:0.005785439114766193\n",
      "Accuracy of the network on the 3268 test sentences:87.63769889840881\n",
      "Time elapsed for epoch:442 is:165.0148003101349\n",
      "[443,   800] loss: 0.000389\n",
      "Learning rate:0.00555360572764041\n",
      "Accuracy of the network on the 3268 test sentences:87.85189718482252\n",
      "Time elapsed for epoch:443 is:164.83054780960083\n",
      "[444,   800] loss: 0.000046\n",
      "Learning rate:0.005358689923425618\n",
      "Accuracy of the network on the 3268 test sentences:87.39290085679315\n",
      "Time elapsed for epoch:444 is:164.86777019500732\n",
      "[445,   800] loss: 0.000164\n",
      "Learning rate:0.005203765640791342\n",
      "Accuracy of the network on the 3268 test sentences:87.27050183598531\n",
      "Time elapsed for epoch:445 is:165.09076499938965\n",
      "[446,   800] loss: 0.000029\n",
      "Learning rate:0.005091276128222005\n",
      "Accuracy of the network on the 3268 test sentences:87.42350061199511\n",
      "Time elapsed for epoch:446 is:165.17399311065674\n",
      "[447,   800] loss: 0.000094\n",
      "Learning rate:0.005022995412528803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 3268 test sentences:87.05630354957161\n",
      "Time elapsed for epoch:447 is:165.1668083667755\n",
      "[448,   800] loss: 0.000076\n",
      "Learning rate:0.00500000032138714\n",
      "Accuracy of the network on the 3268 test sentences:87.91309669522644\n",
      "Time elapsed for epoch:448 is:165.03338193893433\n",
      "[449,   800] loss: 0.000012\n",
      "Learning rate:0.0051790999054764095\n",
      "Accuracy of the network on the 3268 test sentences:87.45410036719706\n",
      "Time elapsed for epoch:449 is:165.21002388000488\n",
      "[450,   800] loss: 0.000676\n",
      "Learning rate:0.0053588739636710485\n",
      "Accuracy of the network on the 3268 test sentences:87.85189718482252\n",
      "Time elapsed for epoch:450 is:164.7052686214447\n",
      "[451,   800] loss: 0.000105\n",
      "Learning rate:0.005538648021865688\n",
      "Accuracy of the network on the 3268 test sentences:88.00489596083231\n",
      "Time elapsed for epoch:451 is:164.97900915145874\n",
      "[452,   800] loss: 0.000249\n",
      "Learning rate:0.005718422080060327\n",
      "Accuracy of the network on the 3268 test sentences:87.57649938800489\n",
      "Time elapsed for epoch:452 is:164.89912629127502\n",
      "[453,   800] loss: 0.000042\n",
      "Learning rate:0.005898196138254966\n",
      "Accuracy of the network on the 3268 test sentences:87.85189718482252\n",
      "Time elapsed for epoch:453 is:164.90392684936523\n",
      "[454,   800] loss: 0.000277\n",
      "Learning rate:0.006077970196449606\n",
      "Accuracy of the network on the 3268 test sentences:87.39290085679315\n",
      "Time elapsed for epoch:454 is:165.15423583984375\n",
      "[455,   800] loss: 0.000501\n",
      "Learning rate:0.006257744254644245\n",
      "Accuracy of the network on the 3268 test sentences:88.31089351285189\n",
      "Time elapsed for epoch:455 is:168.6603844165802\n",
      "[456,   800] loss: 0.000109\n",
      "Learning rate:0.006437518312838884\n",
      "Accuracy of the network on the 3268 test sentences:87.60709914320685\n",
      "Time elapsed for epoch:456 is:168.0054063796997\n",
      "[457,   800] loss: 0.000057\n",
      "Learning rate:0.006617292371033524\n",
      "Accuracy of the network on the 3268 test sentences:87.63769889840881\n",
      "Time elapsed for epoch:457 is:167.47008776664734\n",
      "[458,   800] loss: 0.000116\n",
      "Learning rate:0.006797066429228163\n",
      "Accuracy of the network on the 3268 test sentences:87.79069767441861\n",
      "Time elapsed for epoch:458 is:165.28799700737\n",
      "[459,   800] loss: 0.000158\n",
      "Learning rate:0.0069768404874228016\n",
      "Accuracy of the network on the 3268 test sentences:87.45410036719706\n",
      "Time elapsed for epoch:459 is:164.81583213806152\n",
      "[460,   800] loss: 0.000108\n",
      "Learning rate:0.007156614545617441\n",
      "Accuracy of the network on the 3268 test sentences:87.76009791921665\n",
      "Time elapsed for epoch:460 is:165.0780951976776\n",
      "[461,   800] loss: 0.000312\n",
      "Learning rate:0.00733638860381208\n",
      "Accuracy of the network on the 3268 test sentences:87.60709914320685\n",
      "Time elapsed for epoch:461 is:165.44806933403015\n",
      "[462,   800] loss: 0.000304\n",
      "Learning rate:0.00751616266200672\n",
      "Accuracy of the network on the 3268 test sentences:87.48470012239902\n",
      "Time elapsed for epoch:462 is:165.59273719787598\n",
      "[463,   800] loss: 0.000508\n",
      "Learning rate:0.007695936720201359\n",
      "Accuracy of the network on the 3268 test sentences:87.60709914320685\n",
      "Time elapsed for epoch:463 is:165.70995354652405\n",
      "[464,   800] loss: 0.000088\n",
      "Learning rate:0.007875710778395998\n",
      "Accuracy of the network on the 3268 test sentences:88.03549571603428\n",
      "Time elapsed for epoch:464 is:165.53346943855286\n",
      "[465,   800] loss: 0.000029\n",
      "Learning rate:0.008055484836590637\n",
      "Accuracy of the network on the 3268 test sentences:87.85189718482252\n",
      "Time elapsed for epoch:465 is:165.51941013336182\n",
      "[466,   800] loss: 0.000089\n",
      "Learning rate:0.008235258894785276\n",
      "Accuracy of the network on the 3268 test sentences:87.69889840881272\n",
      "Time elapsed for epoch:466 is:165.16492199897766\n",
      "[467,   800] loss: 0.000357\n",
      "Learning rate:0.008415032952979917\n",
      "Accuracy of the network on the 3268 test sentences:87.79069767441861\n",
      "Time elapsed for epoch:467 is:165.10436415672302\n",
      "[468,   800] loss: 0.000366\n",
      "Learning rate:0.008594807011174556\n",
      "Accuracy of the network on the 3268 test sentences:88.12729498164015\n",
      "Time elapsed for epoch:468 is:165.76943826675415\n",
      "[469,   800] loss: 0.000031\n",
      "Learning rate:0.008774581069369194\n",
      "Accuracy of the network on the 3268 test sentences:87.66829865361078\n",
      "Time elapsed for epoch:469 is:169.45032835006714\n",
      "[470,   800] loss: 0.000390\n",
      "Learning rate:0.008954355127563833\n",
      "Accuracy of the network on the 3268 test sentences:87.69889840881272\n",
      "Time elapsed for epoch:470 is:168.92581295967102\n",
      "[471,   800] loss: 0.000510\n",
      "Learning rate:0.009134129185758472\n",
      "Accuracy of the network on the 3268 test sentences:87.54589963280294\n",
      "Time elapsed for epoch:471 is:165.72601461410522\n",
      "[472,   800] loss: 0.000063\n",
      "Learning rate:0.009313903243953113\n",
      "Accuracy of the network on the 3268 test sentences:87.91309669522644\n",
      "Time elapsed for epoch:472 is:165.9605541229248\n",
      "[473,   800] loss: 0.000039\n",
      "Learning rate:0.00949367730214775\n",
      "Accuracy of the network on the 3268 test sentences:87.48470012239902\n",
      "Time elapsed for epoch:473 is:165.53384733200073\n",
      "[474,   800] loss: 0.000256\n",
      "Learning rate:0.009476764277964676\n",
      "Accuracy of the network on the 3268 test sentences:88.21909424724602\n",
      "Time elapsed for epoch:474 is:165.62412858009338\n",
      "[475,   800] loss: 0.000104\n",
      "Learning rate:0.009424015407240614\n",
      "Accuracy of the network on the 3268 test sentences:87.57649938800489\n",
      "Time elapsed for epoch:475 is:165.69220685958862\n",
      "[476,   800] loss: 0.000095\n",
      "Learning rate:0.009336936474384994\n",
      "Accuracy of the network on the 3268 test sentences:87.79069767441861\n",
      "Time elapsed for epoch:476 is:165.7652416229248\n",
      "[477,   800] loss: 0.000328\n",
      "Learning rate:0.00921690076618738\n",
      "Accuracy of the network on the 3268 test sentences:87.60709914320685\n",
      "Time elapsed for epoch:477 is:165.42072892189026\n",
      "[478,   800] loss: 0.000084\n",
      "Learning rate:0.009065801317471905\n",
      "Accuracy of the network on the 3268 test sentences:87.85189718482252\n",
      "Time elapsed for epoch:478 is:166.4150722026825\n",
      "[479,   800] loss: 0.000046\n",
      "Learning rate:0.008886021056807249\n",
      "Accuracy of the network on the 3268 test sentences:88.73929008567931\n",
      "Saved checkpoint to:./imdb_net_learnable_pooling_sgd_lr_0.00599875_gamma_0.88_500_epochs_32_batch.pth\n",
      "Time elapsed for epoch:479 is:166.00555062294006\n",
      "[480,   800] loss: 0.000007\n",
      "Learning rate:0.008680395226299615\n",
      "Accuracy of the network on the 3268 test sentences:87.72949816401469\n",
      "Time elapsed for epoch:480 is:166.1011655330658\n",
      "[481,   800] loss: 0.000015\n",
      "Learning rate:0.008452166668131027\n",
      "Accuracy of the network on the 3268 test sentences:88.15789473684211\n",
      "Time elapsed for epoch:481 is:166.08775210380554\n",
      "[482,   800] loss: 0.000149\n",
      "Learning rate:0.008204934683000932\n",
      "Accuracy of the network on the 3268 test sentences:87.91309669522644\n",
      "Time elapsed for epoch:482 is:165.71544361114502\n",
      "[483,   800] loss: 0.000092\n",
      "Learning rate:0.007942598267004065\n",
      "Accuracy of the network on the 3268 test sentences:87.85189718482252\n",
      "Time elapsed for epoch:483 is:165.80302453041077\n",
      "[484,   800] loss: 0.000016\n",
      "Learning rate:0.007669294622132871\n",
      "Accuracy of the network on the 3268 test sentences:87.91309669522644\n",
      "Time elapsed for epoch:484 is:166.09771370887756\n",
      "[485,   800] loss: 0.000442\n",
      "Learning rate:0.007389333910130658\n",
      "Accuracy of the network on the 3268 test sentences:88.28029375764994\n",
      "Time elapsed for epoch:485 is:165.6016001701355\n",
      "[486,   800] loss: 0.000111\n",
      "Learning rate:0.007107131278666119\n",
      "Accuracy of the network on the 3268 test sentences:87.69889840881272\n",
      "Time elapsed for epoch:486 is:166.0582709312439\n",
      "[487,   800] loss: 0.000271\n",
      "Learning rate:0.006827137231817133\n",
      "Accuracy of the network on the 3268 test sentences:87.42350061199511\n",
      "Time elapsed for epoch:487 is:165.89838671684265\n",
      "[488,   800] loss: 0.000088\n",
      "Learning rate:0.006553767442962842\n",
      "Accuracy of the network on the 3268 test sentences:87.79069767441861\n",
      "Time elapsed for epoch:488 is:166.1910674571991\n",
      "[489,   800] loss: 0.000524\n",
      "Learning rate:0.006291333116976678\n",
      "Accuracy of the network on the 3268 test sentences:87.51529987760098\n",
      "Time elapsed for epoch:489 is:165.8790261745453\n",
      "[490,   800] loss: 0.000145\n",
      "Learning rate:0.006043972999950109\n",
      "Accuracy of the network on the 3268 test sentences:87.27050183598531\n",
      "Time elapsed for epoch:490 is:165.9496784210205\n",
      "[491,   800] loss: 0.000014\n",
      "Learning rate:0.005815588108694413\n",
      "Accuracy of the network on the 3268 test sentences:88.00489596083231\n",
      "Time elapsed for epoch:491 is:166.04705834388733\n",
      "[492,   800] loss: 0.000027\n",
      "Learning rate:0.005609780209375217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 3268 test sentences:87.97429620563035\n",
      "Time elapsed for epoch:492 is:165.53404545783997\n",
      "[493,   800] loss: 0.000043\n",
      "Learning rate:0.005429795015508462\n",
      "Accuracy of the network on the 3268 test sentences:87.27050183598531\n",
      "Time elapsed for epoch:493 is:166.05896973609924\n",
      "[494,   800] loss: 0.000125\n",
      "Learning rate:0.00527847100111937\n",
      "Accuracy of the network on the 3268 test sentences:87.76009791921665\n",
      "Time elapsed for epoch:494 is:165.83822894096375\n",
      "[495,   800] loss: 0.000049\n",
      "Learning rate:0.005158194636311443\n",
      "Accuracy of the network on the 3268 test sentences:87.72949816401469\n",
      "Time elapsed for epoch:495 is:165.46996188163757\n",
      "[496,   800] loss: 0.000008\n",
      "Learning rate:0.005070862751207318\n",
      "Accuracy of the network on the 3268 test sentences:87.76009791921665\n",
      "Time elapsed for epoch:496 is:165.93262338638306\n",
      "[497,   800] loss: 0.000104\n",
      "Learning rate:0.005017852621804628\n",
      "Accuracy of the network on the 3268 test sentences:87.91309669522644\n",
      "Time elapsed for epoch:497 is:165.4905321598053\n",
      "[498,   800] loss: 0.000020\n",
      "Learning rate:0.005000000249510769\n",
      "Accuracy of the network on the 3268 test sentences:87.60709914320685\n",
      "Time elapsed for epoch:498 is:165.5220079421997\n",
      "[499,   800] loss: 0.000479\n",
      "Learning rate:0.005133697916819241\n",
      "Accuracy of the network on the 3268 test sentences:87.51529987760098\n",
      "Time elapsed for epoch:499 is:167.2611539363861\n",
      "[500,   800] loss: 0.000029\n",
      "Learning rate:0.005267899088030523\n",
      "Accuracy of the network on the 3268 test sentences:88.06609547123622\n",
      "Time elapsed for epoch:500 is:166.14539551734924\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "best_test_accuracy = 0\n",
    "test_accuracy_history = []\n",
    "lrs_history = []\n",
    "train_loss_history = []\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    t1 = time.time()\n",
    "    running_loss = 0.0\n",
    "    i = 0\n",
    "    for data in train_iterator:\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        #inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        texts, labels = data.text.transpose(0,1).to(device), data.label.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = sentiment_trf(texts)\n",
    "        #log_prb = F.log_softmax(outputs, dim=1)\n",
    "        #loss = F.cross_entropy(log_prb, labels, reduction='sum')\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #optimizer.step_and_update_lr()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % n_batches == (n_batches-1):    # print every 2000 mini-batches\n",
    "            curr_train_loss = running_loss / (n_batches)\n",
    "            print('[%d, %5d] loss: %.6f' %\n",
    "                  (epoch + 1, i + 1, curr_train_loss))\n",
    "            train_loss_history.append(curr_train_loss)\n",
    "            lr = optimizer.param_groups[0][\"lr\"]\n",
    "            #lr = optimizer._optimizer.param_groups[0][\"lr\"]\n",
    "            lrs_history.append(lr)\n",
    "            print('Learning rate:{}'.format(lr))\n",
    "            running_loss = 0.0\n",
    "        \n",
    "        if i % (n_batches) == (n_batches-1):\n",
    "            curr_test_accuracy = test_accuracy()\n",
    "            test_accuracy_history.append(curr_test_accuracy)\n",
    "            if(curr_test_accuracy > best_test_accuracy):\n",
    "                best_test_accuracy = curr_test_accuracy\n",
    "                save_checkpoint(sentiment_trf, PATH)\n",
    "        scheduler.step()\n",
    "        i += 1\n",
    "        #warmup_scheduler.dampen()\n",
    "    t2 = time.time()\n",
    "    print('Time elapsed for epoch:{} is:{}'.format(epoch+1, t2-t1))\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best test accuracy is:88.73929008567931\n"
     ]
    }
   ],
   "source": [
    "print('Best test accuracy is:{}'.format(best_test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(range(len(lrs[0::n_batches]))), lrs[0::n_batches])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(range(len(test_accuracy_history))), test_accuracy_history)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37_env",
   "language": "python",
   "name": "python37_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
